{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6rt4c6QLyCDC"
   },
   "source": [
    "## Import Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "4ZxYZNY2yAJV"
   },
   "outputs": [],
   "source": [
    "# Base\n",
    "from time import time\n",
    "from datetime import timedelta\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Graph\n",
    "import networkx as nx\n",
    "# node embedding\n",
    "from node2vec import Node2Vec\n",
    "# sklearn measure\n",
    "from sklearn import metrics\n",
    "\n",
    "# Pytorch\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import init\n",
    "from torch.optim import Adam\n",
    "from torch.optim import SGD\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "9p5HjCc05FxF"
   },
   "outputs": [],
   "source": [
    "class GraphStructure():   \n",
    "    def __init__(self, G):\n",
    "          self.G = G\n",
    "\n",
    "    '''calucate disconnected pairs for negative sample'''\n",
    "    def disconnected_node_pairs(self, node_list):\n",
    "        possible_node_pairs = list()\n",
    "        adjacency_matrix = nx.to_numpy_array(self.G, nodelist=node_list)\n",
    "        for i in range(adjacency_matrix.shape[0]):\n",
    "            for j in range(adjacency_matrix.shape[1]):\n",
    "                if i != j:\n",
    "                    try:\n",
    "                        n = nx.shortest_path_length(G, str(i), str(j))\n",
    "                    except:\n",
    "                        n = 0\n",
    "                    if n <= 2 and adjacency_matrix[i, j] == 0:\n",
    "                        possible_node_pairs.append((node_list[i], node_list[j]))\n",
    "#                 if i != j and adjacency_matrix[i][j] == 0:\n",
    "#                     possible_node_pairs.append((node_list[i], node_list[j]))\n",
    "        return possible_node_pairs\n",
    "\n",
    "    '''calucate removable pairs for positive sample'''\n",
    "    def removable_node_pairs(self, node_pairs_df):\n",
    "        # check whether removing a node pair will cause\n",
    "        # 1: graphic segmentation\n",
    "        # 2: reduce the number of nodes\n",
    "        removable_links_index = list()\n",
    "        original_node_num = self.G.number_of_nodes()\n",
    "        temp_node_pairs_df = node_pairs_df.copy()\n",
    "        for i in tqdm(node_pairs_df.index.values):\n",
    "            temp_G = nx.from_pandas_edgelist(temp_node_pairs_df.drop(index = i), \"node1\", \"node2\", create_using=nx.Graph())\n",
    "            if (nx.number_connected_components(temp_G) == 1) and (temp_G.number_of_nodes() == original_node_num):\n",
    "                removable_links_index.append(i)\n",
    "                temp_node_pairs_df = temp_node_pairs_df.drop(index = i) \n",
    "        return removable_links_index\n",
    "\n",
    "def load_dataset(file_path, split_symbol, read_title=False):\n",
    "    node_pairs = list()\n",
    "    with open(file_path, 'r') as f:\n",
    "        if read_title:\n",
    "            title = f.readline()\n",
    "        for line in f.readlines():\n",
    "            node_pairs.append(list(line.strip().split(split_symbol)))\n",
    "        dataset_df = pd.DataFrame(node_pairs, columns=['node1', 'node2'])\n",
    "    return dataset_df\n",
    "\n",
    "def preprocess(node_pairs_df):\n",
    "    instances = list()\n",
    "    for i, row in node_pairs_df.iterrows():\n",
    "        s_index, t_index, label = row\n",
    "        instance = {\n",
    "            'source': torch.LongTensor(np.array([int(s_index)])),\n",
    "            'target': torch.LongTensor(np.array([int(t_index)])),\n",
    "            'label': torch.FloatTensor(np.array([float(label)]))\n",
    "        }\n",
    "        instances.append(instance)\n",
    "    return instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dzsk_iJRnJMK"
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "-5RAaK_30bWj"
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Random seed\n",
    "    seed = 42\n",
    "    test_sample_ratio = 0.2\n",
    "    sample_rate = 1\n",
    "    random.seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "    node_pairs_df = load_dataset('out.dimacs10-polblogs', split_symbol='\\t', read_title=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UnO26buXBQaQ"
   },
   "source": [
    "## Dataset Splitting and Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CmBPi_4T5FxI",
    "outputId": "5b8abfc7-632f-4210-f2f3-7331b38c1d3c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total # of nodes: 1224\n",
      "total # of edges: 16715\n"
     ]
    }
   ],
   "source": [
    "    # node_pairs = [ pair for pair in zip(node_pairs_df['node1'], node_pairs_df['node2'])]\n",
    "    last_snapshot = nx.from_pandas_edgelist(node_pairs_df, 'node1', 'node2', create_using=nx.Graph())\n",
    "    last_node_pairs_df = pd.DataFrame(list(last_snapshot.edges()), columns=['node1', 'node2']) \n",
    "    print('total # of nodes:', last_snapshot.number_of_nodes())\n",
    "    print('total # of edges:', last_snapshot.number_of_edges())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pu-Rwyp45FxJ"
   },
   "source": [
    "#### Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1J4VAENIKlyJ",
    "outputId": "7842c941-e28e-4e41-dd36-4a7703562c76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test # of negative: 1463522\t# of positive: 3343\n",
      "sample after:\n",
      "# of negative: 3343\t# of positive: 3343\n",
      "\n",
      "        node1 node2  label\n",
      "1341202   781   831      0\n",
      "630683    734  1164      0\n",
      "1036877  1102     9      0\n",
      "1174063  1126   742      0\n",
      "1306388  1113   465      0\n",
      "...       ...   ...    ...\n",
      "16710    1091  1161      1\n",
      "16711    1117  1157      1\n",
      "16712    1168  1210      1\n",
      "16713    1180  1181      1\n",
      "16714    1189  1213      1\n",
      "\n",
      "[6686 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "    # Top 20% edges for test positive sample\n",
    "    test_positive_num = int(last_snapshot.number_of_edges()*test_sample_ratio)\n",
    "    test_positive_df = last_node_pairs_df.tail(test_positive_num).copy()\n",
    "    \n",
    "    # calculate unlink node pairs for test negative sample\n",
    "    test_gs = GraphStructure(last_snapshot)\n",
    "    test_no_edge_pairs = test_gs.disconnected_node_pairs(list(dict.fromkeys(last_node_pairs_df['node1'].to_list()+last_node_pairs_df['node2'].to_list())))\n",
    "    test_no_edge_pairs_df = pd.DataFrame(test_no_edge_pairs, columns=['node1', 'node2'])\n",
    "    test_negative_df = test_no_edge_pairs_df\n",
    "    \n",
    "    # labeling\n",
    "    test_negative_df['label'] = 0\n",
    "    test_positive_df['label'] = 1\n",
    "    print(\"test # of negative: %d\\t# of positive: %d\" % (len(test_negative_df), len(test_positive_df)))\n",
    "    \n",
    "    test_negative_df = test_negative_df.sample(int(len(test_positive_df)*sample_rate), replace=True)\n",
    "    test_dataset_df = test_negative_df.append(test_positive_df)\n",
    "    test_negative_num, test_positive_num = test_dataset_df.label.value_counts()\n",
    "    print(\"sample after:\\n# of negative: %d\\t# of positive: %d\\n\" % (test_positive_num, test_negative_num))\n",
    "    print(test_dataset_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BOOEWqlG5FxL"
   },
   "source": [
    "#### Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qLET0xn8R_qa",
    "outputId": "612bf868-3819-450e-c99d-34c4558b2cdf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of negative: 270896\t# of positive: 3343\n",
      "sample after:\n",
      "# of negative: 3343\t# of positive: 3343\n",
      "\n",
      "       node1 node2  label\n",
      "214392   607   823      0\n",
      "181323   981  1030      0\n",
      "46588    664  1117      0\n",
      "138207   937  1125      0\n",
      "105376   855  1008      0\n",
      "...      ...   ...    ...\n",
      "16710   1091  1161      1\n",
      "16711   1117  1157      1\n",
      "16712   1168  1210      1\n",
      "16713   1180  1181      1\n",
      "16714   1189  1213      1\n",
      "\n",
      "[6686 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "    # Top 80% edges for train positive edge\n",
    "    train_positive_num = last_snapshot.number_of_edges()-test_positive_num\n",
    "    train_positive_df = test_positive_df.head(train_positive_num).copy()\n",
    "    train_snapshot = nx.from_pandas_edgelist(train_positive_df, 'node1', 'node2', create_using=nx.Graph())\n",
    "    \n",
    "    # remove edges with test positive sample for training snapshot\n",
    "    train_snapshot = last_snapshot.copy()\n",
    "    for pair in zip(test_positive_df['node1'], test_positive_df['node2']):\n",
    "        train_snapshot.remove_edge(*pair)\n",
    "    \n",
    "    # calculate unlink node pairs for train negative sample\n",
    "    train_gs = GraphStructure(train_snapshot)\n",
    "    train_no_edge_pairs = train_gs.disconnected_node_pairs(list(dict.fromkeys(train_positive_df['node1'].to_list()+train_positive_df['node2'].to_list())))\n",
    "    train_no_edge_pairs_df = pd.DataFrame(train_no_edge_pairs, columns=['node1', 'node2'])\n",
    "    train_negative_df = train_no_edge_pairs_df\n",
    "    \n",
    "    # labeling\n",
    "    train_negative_df['label'] = 0\n",
    "    train_positive_df['label'] = 1\n",
    "    print(\"# of negative: %d\\t# of positive: %d\" % (len(train_negative_df), len(train_positive_df)))\n",
    "\n",
    "    train_negative_df = train_negative_df.sample(len(train_positive_df), replace=True)\n",
    "    train_dataset_df = train_negative_df.append(train_positive_df)\n",
    "    train_positive_num, train_negative_num = train_dataset_df.label.value_counts()\n",
    "    print(\"sample after:\\n# of negative: %d\\t# of positive: %d\\n\" % (train_positive_num, train_negative_num))\n",
    "    print(train_dataset_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T890E3P55FxM"
   },
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "geVaSGGd5FxM",
    "outputId": "254e62c6-7af6-4dd2-bb3a-7818d7b2ddc3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of test instances: 840\n",
      "# of train instances: 840\n",
      "# of total instances: 1680\n"
     ]
    }
   ],
   "source": [
    "    test_instances = preprocess(test_dataset_df)\n",
    "    train_instances = preprocess(train_dataset_df)\n",
    "    \n",
    "    print('# of test instances:', len(test_instances))\n",
    "    print('# of train instances:', len(train_instances))\n",
    "    print('# of total instances:', (len(train_instances)+len(test_instances)))\n",
    "#     test_instances = preprocess(test_dataset_df)\n",
    "#     valid_instances = preprocess(valid_dataset_df)\n",
    "#     train_instances = preprocess(train_dataset_df)\n",
    "    \n",
    "#     print('# of test instances:', len(test_instances))\n",
    "#     print('# of valid instances:', len(valid_stances))\n",
    "#     print('# of train instances:', len(train_instances))\n",
    "#     print('# of total instances:', (len(train_instances)+len(valid_instances)+len(test_instances)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7rTSUoWMOmeZ"
   },
   "source": [
    "## Graph Node Embedding with Node2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 83,
     "referenced_widgets": [
      "f152c8a5153c4235bd37d9d47cf48830",
      "b7db93717d7643e4bf0777503d87cab2",
      "de30f42132da46f082cee8dfcf051c2f",
      "0e7ae792d1264c1db57e178901615630",
      "019bfd6e6d68453ab8302e32ff4c693e",
      "a2ec94874bad43b0a297e6e368641ce8",
      "52dda8a6eec84634acb241491d4b8e71",
      "8b3f14adca0e4d919011a7cae002d3fd"
     ]
    },
    "id": "K-91l9ElOnDw",
    "outputId": "0cd5aabe-f6b4-491e-e1d4-1916bfbcf847",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f459a1d8a7b444809fb3cdbfe69918ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Computing transition probabilities'), FloatProgress(value=0.0, max=620.0), HTML(val…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1):   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1): 100%|██████████| 10/10 [00:12<00:00,  1.27s/it]\n"
     ]
    }
   ],
   "source": [
    "    node2vec = Node2Vec(train_snapshot, dimensions=128, walk_length=80, num_walks=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "bqsoVI4PtZXY"
   },
   "outputs": [],
   "source": [
    "    n2v_model = node2vec.fit(window=10, min_count=1, batch_words=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E1A7aBo65FxN",
    "outputId": "7e122291-2177-4c35-9796-d90e8f6e95e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620, 128)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    node_embedding = n2v_model.wv.vectors\n",
    "    node_embedding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "frU6f-Z45FxO"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Dm4wkWxc5FxO"
   },
   "outputs": [],
   "source": [
    "    class NodePairDataset(Dataset):\n",
    "        def __init__(self, instances):\n",
    "            self.instances = instances\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.instances)\n",
    "\n",
    "        def __getitem__(self, i):\n",
    "            instance = self.instances[i]\n",
    "            source = instance['source']\n",
    "            target = instance['target']\n",
    "            label = instance['label']\n",
    "            return source, target, label\n",
    "        \n",
    "    def collate_fn(batch):\n",
    "        source, target, labels = zip(*batch)\n",
    "        source = torch.stack(source)\n",
    "        target = torch.stack(target)\n",
    "        labels = torch.stack(labels)\n",
    "        return source, target, labels\n",
    "\n",
    "    def get_dataloader(instances, collate_fn=collate_fn,batch_size=1, num_workers=2):\n",
    "        dataset = NodePairDataset(instances)\n",
    "        dataloader = DataLoader(dataset, collate_fn=collate_fn, shuffle=True, batch_size=batch_size, num_workers=num_workers)\n",
    "        return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "bg6RaO_85FxO"
   },
   "outputs": [],
   "source": [
    "    class LinkEmbedding(nn.Module):\n",
    "        def __init__(self, inputs_dim, output_dim):\n",
    "            super(LinkEmbedding, self).__init__()\n",
    "            self.weight = nn.Parameter(nn.init.xavier_uniform_(torch.empty(inputs_dim, output_dim)))\n",
    "            \n",
    "            \n",
    "        def forward(self, hidden_state, source, target):\n",
    "            propagation = torch.mul(hidden_state[source, :], hidden_state[target, :])\n",
    "            propagation = propagation.matmul(self.weight)\n",
    "            return propagation\n",
    "    \n",
    "    class GraphConvolution(nn.Module):\n",
    "        def __init__(self, inputs_dim, hidden_dim):\n",
    "            super(GraphConvolution, self).__init__()\n",
    "            self.weight = nn.Parameter(nn.init.kaiming_normal_(torch.empty(inputs_dim, hidden_dim), mode='fan_in', nonlinearity='relu'))\n",
    "            # self.weight = nn.Parameter(nn.init.xavier_uniform_(torch.empty(inputs_dim, hidden_dim)))\n",
    "            \n",
    "            \n",
    "        def forward(self, input_features, adj_matrix):\n",
    "            # aggregate \n",
    "            aggregate  = torch.mm(input_features, self.weight)\n",
    "            propagation = torch.mm(adj_matrix, aggregate)\n",
    "            return propagation\n",
    "        \n",
    "    class GCN(nn.Module):\n",
    "        def __init__(self, inputs_dim, hidden_dim, output_dim):\n",
    "            super(GCN, self).__init__()\n",
    "            self.gcn_layer1 = GraphConvolution(inputs_dim, hidden_dim)\n",
    "            self.gcn_layer2 = GraphConvolution(hidden_dim, hidden_dim)\n",
    "            self.link_embed_layer = LinkEmbedding(hidden_dim, output_dim)\n",
    "            self.relu = nn.ReLU()\n",
    "            self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        def forward(self, input_features, adj_matrix, source, target):\n",
    "            hidden_state = self.relu(self.gcn_layer1(input_features, adj_matrix))\n",
    "            hidden_state = self.gcn_layer2(hidden_state, adj_matrix)\n",
    "            hidden_state = self.link_embed_layer(hidden_state, source, target)\n",
    "            return hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "2IAyLfi25FxO"
   },
   "outputs": [],
   "source": [
    "    class GCNTrainer():\n",
    "        def __init__(self, features, adj_matrix, train_instances, valid_instances=None, test_instances=None, \n",
    "            hidden_dim=16, epoch=1, max_patience=0, learning_rate=1e-2, batch_size=1,num_workers=2, valid=False):\n",
    "\n",
    "            # parameters\n",
    "            self.valid = valid\n",
    "            self.epochs = epoch\n",
    "            self.learning_rate = learning_rate\n",
    "            self.batch_size = batch_size\n",
    "            self.num_workers = num_workers\n",
    "            # early stop\n",
    "            self.best_valid_loss = 1e10\n",
    "            self.max_patience = max_patience\n",
    "            self.patience = 0\n",
    "\n",
    "            # setup cuda device\n",
    "            self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "            # dataset\n",
    "            self.train_instances = train_instances\n",
    "            self.valid_instances = valid_instances\n",
    "            self.test_instances = test_instances\n",
    "            self.features = torch.FloatTensor(features).cuda()\n",
    "            self.adj_matrix = torch.FloatTensor(self.normalize(adj_matrix)).cuda()\n",
    "            \n",
    "            # GCN Model\n",
    "            self.model = GCN(self.features.shape[1], hidden_dim, output_dim=1)\n",
    "            self.model.cuda()\n",
    "            # print(self.model)\n",
    "\n",
    "            # Adam optimizer with hyper-parameter\n",
    "            # self.optimizer = SGD(self.model.parameters(), lr=self.learning_rate)\n",
    "            self.optimizer = Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "\n",
    "            # Binary Cross Entropy with Loss for criterion\n",
    "            self.criterion = nn.BCEWithLogitsLoss()\n",
    "        \n",
    "\n",
    "        def normalize(self, A):\n",
    "            '''\n",
    "            :var I: identity matrix\n",
    "            :var A: adjacency matrix\n",
    "            :var D: degree matrix\n",
    "            :var A_hat: adding self-loops\n",
    "            :var D_inv: degree inverse matrix\n",
    "            '''\n",
    "            I = np.matrix(np.identity(A.shape[0]))\n",
    "            A_hat = I + A\n",
    "            \n",
    "            D = np.array(np.sum(A, axis=0))\n",
    "            D_inv = D**-0.5\n",
    "            D_inv[np.isinf(D_inv)] = 0.\n",
    "            D_inv = np.diag(D_inv)\n",
    "\n",
    "            A_hat = D_inv * A_hat * D_inv\n",
    "            return A_hat\n",
    "        \n",
    "        def accuracy(self, predicts, labels):\n",
    "            predicts_labels = torch.round(torch.sigmoid(predicts))\n",
    "            total_correct = (predicts_labels == labels).sum().float()\n",
    "            return torch.round((total_correct / labels.shape[0]) * 100)\n",
    "\n",
    "        def train(self):\n",
    "            start_time = time()\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            train_dataloader = get_dataloader(self.train_instances, collate_fn=collate_fn, batch_size=self.batch_size, num_workers=self.num_workers)\n",
    "            for epoch in range(self.epochs):\n",
    "                self.model.train()\n",
    "                epoch_loss, epoch_acc = 0, 0\n",
    "                ''' train '''\n",
    "                for i, batch in enumerate(train_dataloader, start=1):\n",
    "                    batch = (tensor.cuda() for tensor in batch)\n",
    "                    source, target, labels = batch\n",
    "                    # forward\n",
    "                    # feature: all node embedding\n",
    "                    outputs = self.model(self.features, self.adj_matrix, source, target)\n",
    "                    outputs = outputs.reshape(labels.size())\n",
    "                    # backward\n",
    "                    loss = self.criterion(outputs, labels)\n",
    "                    acc = self.accuracy(outputs, labels)\n",
    "                    epoch_loss += loss.item()\n",
    "                    epoch_acc += acc\n",
    "                    \n",
    "                    loss.backward()\n",
    "                    # optimize\n",
    "                    self.optimizer.step()\n",
    "                    self.optimizer.zero_grad()\n",
    "                    \n",
    "                    # Progressbar\n",
    "                    elapsed_time = time() - start_time\n",
    "                    elapsed_time = timedelta(seconds=int(elapsed_time))\n",
    "                    # print(\"Epoch %d/%d | loss: %.6f | acc: %f | batch: [%d/%d] | %s\" % (epoch+1, self.epochs, loss, acc, i, len(train_dataloader), elapsed_time))\n",
    "                \n",
    "                print(\"Epoch %d/%d - train_loss: %.6f - train_acc: %.2f%%\" \n",
    "                      % (epoch+1, self.epochs, epoch_loss/len(train_dataloader), epoch_acc/len(train_dataloader)))\n",
    "                \n",
    "                ''' validate '''\n",
    "                if self.valid:\n",
    "                    valid_loss, valid_acc = self.validate()\n",
    "                    elapsed_time = time() - start_time\n",
    "                    elapsed_time = timedelta(seconds=int(elapsed_time))\n",
    "                    print(\"Epoch %d/%d - valid_loss: %.6f - valid_acc: %.2f%%\" % (epoch+1, self.epochs, valid_loss, valid_acc))\n",
    "\n",
    "                    # early stoping\n",
    "                    if valid_loss < self.best_valid_loss:\n",
    "                        self.patience = 0\n",
    "                        self.best_valid_loss = valid_loss\n",
    "                    else:\n",
    "                        self.patience += 1\n",
    "\n",
    "                    if self.patience > self.max_patience:\n",
    "                        print('Earlystop at epoch %d' % (epoch+1))\n",
    "                        break\n",
    "\n",
    "\n",
    "        def validate(self):\n",
    "            total_loss, total_acc = 0, 0\n",
    "            self.model.eval()\n",
    "            with torch.no_grad():\n",
    "                valid_dataloader = get_dataloader(self.valid_instances, collate_fn=collate_fn, batch_size=self.batch_size, num_workers=self.num_workers)\n",
    "                for batch in valid_dataloader:\n",
    "                    batch = (tensor.cuda() for tensor in batch)\n",
    "                    source, target, labels = batch\n",
    "                    outputs = self.model(self.features, self.adj_matrix, source, target)\n",
    "                    outputs = outputs.reshape(labels.size())\n",
    "                    loss = self.criterion(outputs, labels)\n",
    "                    # loss and accuracy\n",
    "                    total_loss += loss.item()\n",
    "                    total_acc += self.accuracy(outputs, labels)\n",
    "            \n",
    "            total_loss /= len(valid_dataloader)\n",
    "            total_acc /= len(valid_dataloader)\n",
    "            return float(total_loss), float(total_acc)\n",
    "\n",
    "        def test(self):\n",
    "            total_loss, total_acc, auc = 0, 0, 0\n",
    "            total_predicts, total_labels = list(), list()\n",
    "            self.model.eval()\n",
    "            with torch.no_grad():\n",
    "                test_dataloader = get_dataloader(self.test_instances, collate_fn=collate_fn, batch_size=self.batch_size, num_workers=self.num_workers)\n",
    "                for batch in test_dataloader:\n",
    "                    batch = (tensor.cuda() for tensor in batch)\n",
    "                    source, target, labels = batch\n",
    "                    outputs = self.model(self.features, self.adj_matrix, source, target)\n",
    "                    outputs = outputs.reshape(labels.size())\n",
    "                    # auc\n",
    "                    total_predicts += torch.round(torch.sigmoid(outputs.cpu())).squeeze().numpy().tolist()\n",
    "                    total_labels += torch.round(torch.sigmoid(labels.cpu())).squeeze().numpy().tolist()\n",
    "                    loss = self.criterion(outputs, labels)\n",
    "                    # loss and accuracy\n",
    "                    total_loss += loss.item()\n",
    "                    total_acc += self.accuracy(outputs, labels)\n",
    "            \n",
    "            total_loss /= len(test_dataloader)\n",
    "            total_acc /= len(test_dataloader)\n",
    "            \n",
    "            fpr, tpr, thresholds = metrics.roc_curve(total_labels, total_predicts, pos_label=1)\n",
    "            auc = metrics.auc(fpr, tpr)\n",
    "            return float(total_loss), float(total_acc), auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oTS4-KQH5FxP",
    "outputId": "c4fc3b90-f503-4301-a524-09298c72c4e8",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 1. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "    adj_matrix = nx.to_numpy_array(train_snapshot)\n",
    "    print(adj_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O_FrH6kq5FxP",
    "outputId": "844b1e6b-2a5e-42a3-c554-c26135d2266f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-1386f989da06>:51: RuntimeWarning: divide by zero encountered in power\n",
      "  D_inv = D**-0.5\n"
     ]
    }
   ],
   "source": [
    "    trainer = GCNTrainer(features=node_embedding, adj_matrix=adj_matrix, \n",
    "                         train_instances=train_instances, \n",
    "                         valid_instances=None,\n",
    "                         test_instances=test_instances,\n",
    "                         hidden_dim=64, epoch=300,learning_rate=1e-2, batch_size=128, num_workers=2, valid=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4thQlWPX38zg",
    "outputId": "e0c37871-cbe3-44cc-cabc-24b47d3f4c7e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300 - train_loss: 0.739812 - train_acc: 48.29%\n",
      "Epoch 2/300 - train_loss: 0.686383 - train_acc: 53.86%\n",
      "Epoch 3/300 - train_loss: 0.681158 - train_acc: 57.43%\n",
      "Epoch 4/300 - train_loss: 0.667159 - train_acc: 58.43%\n",
      "Epoch 5/300 - train_loss: 0.674555 - train_acc: 57.29%\n",
      "Epoch 6/300 - train_loss: 0.672268 - train_acc: 54.00%\n",
      "Epoch 7/300 - train_loss: 0.660025 - train_acc: 58.71%\n",
      "Epoch 8/300 - train_loss: 0.652384 - train_acc: 58.43%\n",
      "Epoch 9/300 - train_loss: 0.640271 - train_acc: 59.71%\n",
      "Epoch 10/300 - train_loss: 0.634239 - train_acc: 58.86%\n",
      "Epoch 11/300 - train_loss: 0.639702 - train_acc: 59.86%\n",
      "Epoch 12/300 - train_loss: 0.635729 - train_acc: 59.86%\n",
      "Epoch 13/300 - train_loss: 0.621265 - train_acc: 63.57%\n",
      "Epoch 14/300 - train_loss: 0.607730 - train_acc: 61.29%\n",
      "Epoch 15/300 - train_loss: 0.595553 - train_acc: 62.14%\n",
      "Epoch 16/300 - train_loss: 0.581287 - train_acc: 64.00%\n",
      "Epoch 17/300 - train_loss: 0.578854 - train_acc: 63.00%\n",
      "Epoch 18/300 - train_loss: 0.567964 - train_acc: 66.86%\n",
      "Epoch 19/300 - train_loss: 0.566143 - train_acc: 67.14%\n",
      "Epoch 20/300 - train_loss: 0.564822 - train_acc: 66.29%\n",
      "Epoch 21/300 - train_loss: 0.558773 - train_acc: 65.29%\n",
      "Epoch 22/300 - train_loss: 0.553266 - train_acc: 67.00%\n",
      "Epoch 23/300 - train_loss: 0.543309 - train_acc: 68.00%\n",
      "Epoch 24/300 - train_loss: 0.537601 - train_acc: 67.14%\n",
      "Epoch 25/300 - train_loss: 0.511676 - train_acc: 69.00%\n",
      "Epoch 26/300 - train_loss: 0.506178 - train_acc: 68.43%\n",
      "Epoch 27/300 - train_loss: 0.502124 - train_acc: 71.00%\n",
      "Epoch 28/300 - train_loss: 0.502479 - train_acc: 70.14%\n",
      "Epoch 29/300 - train_loss: 0.499960 - train_acc: 70.14%\n",
      "Epoch 30/300 - train_loss: 0.486854 - train_acc: 71.14%\n",
      "Epoch 31/300 - train_loss: 0.495757 - train_acc: 70.71%\n",
      "Epoch 32/300 - train_loss: 0.505133 - train_acc: 71.00%\n",
      "Epoch 33/300 - train_loss: 0.499504 - train_acc: 69.29%\n",
      "Epoch 34/300 - train_loss: 0.498004 - train_acc: 71.71%\n",
      "Epoch 35/300 - train_loss: 0.490542 - train_acc: 71.43%\n",
      "Epoch 36/300 - train_loss: 0.477083 - train_acc: 71.14%\n",
      "Epoch 37/300 - train_loss: 0.465013 - train_acc: 72.57%\n",
      "Epoch 38/300 - train_loss: 0.448003 - train_acc: 73.71%\n",
      "Epoch 39/300 - train_loss: 0.442303 - train_acc: 74.29%\n",
      "Epoch 40/300 - train_loss: 0.502686 - train_acc: 70.57%\n",
      "Epoch 41/300 - train_loss: 0.455394 - train_acc: 73.43%\n",
      "Epoch 42/300 - train_loss: 0.461012 - train_acc: 73.71%\n",
      "Epoch 43/300 - train_loss: 0.437722 - train_acc: 73.86%\n",
      "Epoch 44/300 - train_loss: 0.434297 - train_acc: 73.14%\n",
      "Epoch 45/300 - train_loss: 0.420586 - train_acc: 74.29%\n",
      "Epoch 46/300 - train_loss: 0.396131 - train_acc: 76.29%\n",
      "Epoch 47/300 - train_loss: 0.394154 - train_acc: 76.71%\n",
      "Epoch 48/300 - train_loss: 0.375253 - train_acc: 77.00%\n",
      "Epoch 49/300 - train_loss: 0.355600 - train_acc: 78.14%\n",
      "Epoch 50/300 - train_loss: 0.362418 - train_acc: 78.00%\n",
      "Epoch 51/300 - train_loss: 0.367180 - train_acc: 77.43%\n",
      "Epoch 52/300 - train_loss: 0.363213 - train_acc: 77.29%\n",
      "Epoch 53/300 - train_loss: 0.457639 - train_acc: 75.86%\n",
      "Epoch 54/300 - train_loss: 0.421296 - train_acc: 75.43%\n",
      "Epoch 55/300 - train_loss: 0.430441 - train_acc: 75.00%\n",
      "Epoch 56/300 - train_loss: 0.418325 - train_acc: 75.57%\n",
      "Epoch 57/300 - train_loss: 0.396916 - train_acc: 76.43%\n",
      "Epoch 58/300 - train_loss: 0.377569 - train_acc: 78.14%\n",
      "Epoch 59/300 - train_loss: 0.360904 - train_acc: 78.57%\n",
      "Epoch 60/300 - train_loss: 0.350728 - train_acc: 79.14%\n",
      "Epoch 61/300 - train_loss: 0.350797 - train_acc: 78.14%\n",
      "Epoch 62/300 - train_loss: 0.348767 - train_acc: 79.43%\n",
      "Epoch 63/300 - train_loss: 0.349718 - train_acc: 78.00%\n",
      "Epoch 64/300 - train_loss: 0.360094 - train_acc: 78.57%\n",
      "Epoch 65/300 - train_loss: 0.360081 - train_acc: 78.57%\n",
      "Epoch 66/300 - train_loss: 0.360095 - train_acc: 78.57%\n",
      "Epoch 67/300 - train_loss: 0.377426 - train_acc: 77.71%\n",
      "Epoch 68/300 - train_loss: 0.422536 - train_acc: 76.00%\n",
      "Epoch 69/300 - train_loss: 0.431385 - train_acc: 76.29%\n",
      "Epoch 70/300 - train_loss: 0.416238 - train_acc: 75.86%\n",
      "Epoch 71/300 - train_loss: 0.359680 - train_acc: 79.00%\n",
      "Epoch 72/300 - train_loss: 0.349404 - train_acc: 79.29%\n",
      "Epoch 73/300 - train_loss: 0.351756 - train_acc: 78.86%\n",
      "Epoch 74/300 - train_loss: 0.335156 - train_acc: 80.14%\n",
      "Epoch 75/300 - train_loss: 0.331096 - train_acc: 80.14%\n",
      "Epoch 76/300 - train_loss: 0.328446 - train_acc: 79.57%\n",
      "Epoch 77/300 - train_loss: 0.318618 - train_acc: 80.43%\n",
      "Epoch 78/300 - train_loss: 0.317930 - train_acc: 79.86%\n",
      "Epoch 79/300 - train_loss: 0.323288 - train_acc: 79.43%\n",
      "Epoch 80/300 - train_loss: 0.327531 - train_acc: 79.57%\n",
      "Epoch 81/300 - train_loss: 0.311006 - train_acc: 80.71%\n",
      "Epoch 82/300 - train_loss: 0.312176 - train_acc: 80.57%\n",
      "Epoch 83/300 - train_loss: 0.326093 - train_acc: 79.71%\n",
      "Epoch 84/300 - train_loss: 0.316645 - train_acc: 80.43%\n",
      "Epoch 85/300 - train_loss: 0.336090 - train_acc: 79.57%\n",
      "Epoch 86/300 - train_loss: 0.336371 - train_acc: 80.57%\n",
      "Epoch 87/300 - train_loss: 0.317586 - train_acc: 80.14%\n",
      "Epoch 88/300 - train_loss: 0.311035 - train_acc: 81.00%\n",
      "Epoch 89/300 - train_loss: 0.311334 - train_acc: 80.43%\n",
      "Epoch 90/300 - train_loss: 0.310810 - train_acc: 81.00%\n",
      "Epoch 91/300 - train_loss: 0.303797 - train_acc: 81.14%\n",
      "Epoch 92/300 - train_loss: 0.307503 - train_acc: 81.14%\n",
      "Epoch 93/300 - train_loss: 0.302770 - train_acc: 80.86%\n",
      "Epoch 94/300 - train_loss: 0.295686 - train_acc: 80.86%\n",
      "Epoch 95/300 - train_loss: 0.286510 - train_acc: 81.29%\n",
      "Epoch 96/300 - train_loss: 0.284600 - train_acc: 81.71%\n",
      "Epoch 97/300 - train_loss: 0.296299 - train_acc: 80.71%\n",
      "Epoch 98/300 - train_loss: 0.295384 - train_acc: 80.71%\n",
      "Epoch 99/300 - train_loss: 0.304204 - train_acc: 80.43%\n",
      "Epoch 100/300 - train_loss: 0.318221 - train_acc: 81.29%\n",
      "Epoch 101/300 - train_loss: 0.335626 - train_acc: 80.00%\n",
      "Epoch 102/300 - train_loss: 0.332008 - train_acc: 79.71%\n",
      "Epoch 103/300 - train_loss: 0.345172 - train_acc: 79.43%\n",
      "Epoch 104/300 - train_loss: 0.326928 - train_acc: 80.71%\n",
      "Epoch 105/300 - train_loss: 0.311951 - train_acc: 79.86%\n",
      "Epoch 106/300 - train_loss: 0.315910 - train_acc: 81.14%\n",
      "Epoch 107/300 - train_loss: 0.299471 - train_acc: 80.86%\n",
      "Epoch 108/300 - train_loss: 0.297660 - train_acc: 80.71%\n",
      "Epoch 109/300 - train_loss: 0.296012 - train_acc: 81.43%\n",
      "Epoch 110/300 - train_loss: 0.281556 - train_acc: 81.14%\n",
      "Epoch 111/300 - train_loss: 0.282554 - train_acc: 80.86%\n",
      "Epoch 112/300 - train_loss: 0.281261 - train_acc: 80.86%\n",
      "Epoch 113/300 - train_loss: 0.277087 - train_acc: 82.00%\n",
      "Epoch 114/300 - train_loss: 0.272425 - train_acc: 81.86%\n",
      "Epoch 115/300 - train_loss: 0.277901 - train_acc: 82.14%\n",
      "Epoch 116/300 - train_loss: 0.274688 - train_acc: 81.71%\n",
      "Epoch 117/300 - train_loss: 0.282647 - train_acc: 82.29%\n",
      "Epoch 118/300 - train_loss: 0.273911 - train_acc: 82.00%\n",
      "Epoch 119/300 - train_loss: 0.274159 - train_acc: 81.43%\n",
      "Epoch 120/300 - train_loss: 0.278094 - train_acc: 82.14%\n",
      "Epoch 121/300 - train_loss: 0.270513 - train_acc: 82.29%\n",
      "Epoch 122/300 - train_loss: 0.275915 - train_acc: 82.29%\n",
      "Epoch 123/300 - train_loss: 0.270947 - train_acc: 82.43%\n",
      "Epoch 124/300 - train_loss: 0.553327 - train_acc: 77.86%\n",
      "Epoch 125/300 - train_loss: 1.041957 - train_acc: 71.57%\n",
      "Epoch 126/300 - train_loss: 0.966108 - train_acc: 68.71%\n",
      "Epoch 127/300 - train_loss: 0.718572 - train_acc: 69.43%\n",
      "Epoch 128/300 - train_loss: 0.616379 - train_acc: 68.00%\n",
      "Epoch 129/300 - train_loss: 0.561491 - train_acc: 67.14%\n",
      "Epoch 130/300 - train_loss: 0.537684 - train_acc: 68.71%\n",
      "Epoch 131/300 - train_loss: 0.521990 - train_acc: 69.86%\n",
      "Epoch 132/300 - train_loss: 0.507191 - train_acc: 71.00%\n",
      "Epoch 133/300 - train_loss: 0.488355 - train_acc: 71.43%\n",
      "Epoch 134/300 - train_loss: 0.464387 - train_acc: 74.00%\n",
      "Epoch 135/300 - train_loss: 0.449511 - train_acc: 73.43%\n",
      "Epoch 136/300 - train_loss: 0.433115 - train_acc: 74.57%\n",
      "Epoch 137/300 - train_loss: 0.431976 - train_acc: 74.29%\n",
      "Epoch 138/300 - train_loss: 0.413760 - train_acc: 74.57%\n",
      "Epoch 139/300 - train_loss: 0.400643 - train_acc: 75.43%\n",
      "Epoch 140/300 - train_loss: 0.400287 - train_acc: 77.14%\n",
      "Epoch 141/300 - train_loss: 0.390247 - train_acc: 76.57%\n",
      "Epoch 142/300 - train_loss: 0.376255 - train_acc: 77.86%\n",
      "Epoch 143/300 - train_loss: 0.380182 - train_acc: 76.86%\n",
      "Epoch 144/300 - train_loss: 0.367978 - train_acc: 77.43%\n",
      "Epoch 145/300 - train_loss: 0.357567 - train_acc: 77.86%\n",
      "Epoch 146/300 - train_loss: 0.358488 - train_acc: 78.57%\n",
      "Epoch 147/300 - train_loss: 0.349235 - train_acc: 79.43%\n",
      "Epoch 148/300 - train_loss: 0.339932 - train_acc: 79.14%\n",
      "Epoch 149/300 - train_loss: 0.338116 - train_acc: 79.71%\n",
      "Epoch 150/300 - train_loss: 0.331216 - train_acc: 79.43%\n",
      "Epoch 151/300 - train_loss: 0.328432 - train_acc: 79.86%\n",
      "Epoch 152/300 - train_loss: 0.325898 - train_acc: 80.00%\n",
      "Epoch 153/300 - train_loss: 0.320289 - train_acc: 80.29%\n",
      "Epoch 154/300 - train_loss: 0.312097 - train_acc: 80.86%\n",
      "Epoch 155/300 - train_loss: 0.315592 - train_acc: 80.43%\n",
      "Epoch 156/300 - train_loss: 0.313422 - train_acc: 80.29%\n",
      "Epoch 157/300 - train_loss: 0.382962 - train_acc: 78.14%\n",
      "Epoch 158/300 - train_loss: 0.358097 - train_acc: 78.57%\n",
      "Epoch 159/300 - train_loss: 0.372735 - train_acc: 78.71%\n",
      "Epoch 160/300 - train_loss: 0.342380 - train_acc: 78.00%\n",
      "Epoch 161/300 - train_loss: 0.334905 - train_acc: 79.29%\n",
      "Epoch 162/300 - train_loss: 0.321236 - train_acc: 80.14%\n",
      "Epoch 163/300 - train_loss: 0.311944 - train_acc: 80.86%\n",
      "Epoch 164/300 - train_loss: 0.308681 - train_acc: 80.71%\n",
      "Epoch 165/300 - train_loss: 0.295764 - train_acc: 81.29%\n",
      "Epoch 166/300 - train_loss: 0.302882 - train_acc: 80.86%\n",
      "Epoch 167/300 - train_loss: 0.289044 - train_acc: 81.86%\n",
      "Epoch 168/300 - train_loss: 0.288250 - train_acc: 82.29%\n",
      "Epoch 169/300 - train_loss: 0.292215 - train_acc: 81.29%\n",
      "Epoch 170/300 - train_loss: 0.283281 - train_acc: 81.86%\n",
      "Epoch 171/300 - train_loss: 0.296915 - train_acc: 81.71%\n",
      "Epoch 172/300 - train_loss: 0.305633 - train_acc: 80.86%\n",
      "Epoch 173/300 - train_loss: 0.290685 - train_acc: 81.57%\n",
      "Epoch 174/300 - train_loss: 0.301420 - train_acc: 81.71%\n",
      "Epoch 175/300 - train_loss: 0.349432 - train_acc: 80.71%\n",
      "Epoch 176/300 - train_loss: 0.318107 - train_acc: 81.00%\n",
      "Epoch 177/300 - train_loss: 0.309636 - train_acc: 81.29%\n",
      "Epoch 178/300 - train_loss: 0.321758 - train_acc: 79.57%\n",
      "Epoch 179/300 - train_loss: 0.328007 - train_acc: 80.57%\n",
      "Epoch 180/300 - train_loss: 0.324031 - train_acc: 80.71%\n",
      "Epoch 181/300 - train_loss: 0.321551 - train_acc: 79.71%\n",
      "Epoch 182/300 - train_loss: 0.335764 - train_acc: 80.71%\n",
      "Epoch 183/300 - train_loss: 0.309756 - train_acc: 81.14%\n",
      "Epoch 184/300 - train_loss: 0.310982 - train_acc: 81.29%\n",
      "Epoch 185/300 - train_loss: 0.332538 - train_acc: 79.71%\n",
      "Epoch 186/300 - train_loss: 0.324064 - train_acc: 79.57%\n",
      "Epoch 187/300 - train_loss: 0.296702 - train_acc: 80.71%\n",
      "Epoch 188/300 - train_loss: 0.292139 - train_acc: 80.86%\n",
      "Epoch 189/300 - train_loss: 0.285473 - train_acc: 81.29%\n",
      "Epoch 190/300 - train_loss: 0.286155 - train_acc: 81.14%\n",
      "Epoch 191/300 - train_loss: 0.279850 - train_acc: 82.14%\n",
      "Epoch 192/300 - train_loss: 0.272881 - train_acc: 82.29%\n",
      "Epoch 193/300 - train_loss: 0.272343 - train_acc: 82.57%\n",
      "Epoch 194/300 - train_loss: 0.268574 - train_acc: 82.29%\n",
      "Epoch 195/300 - train_loss: 0.270103 - train_acc: 82.29%\n",
      "Epoch 196/300 - train_loss: 0.275527 - train_acc: 82.14%\n",
      "Epoch 197/300 - train_loss: 0.266565 - train_acc: 82.57%\n",
      "Epoch 198/300 - train_loss: 0.266899 - train_acc: 82.00%\n",
      "Epoch 199/300 - train_loss: 0.270491 - train_acc: 82.00%\n",
      "Epoch 200/300 - train_loss: 0.271220 - train_acc: 82.14%\n",
      "Epoch 201/300 - train_loss: 0.264697 - train_acc: 82.29%\n",
      "Epoch 202/300 - train_loss: 0.264833 - train_acc: 82.43%\n",
      "Epoch 203/300 - train_loss: 0.268539 - train_acc: 82.57%\n",
      "Epoch 204/300 - train_loss: 0.282808 - train_acc: 81.86%\n",
      "Epoch 205/300 - train_loss: 0.281939 - train_acc: 82.14%\n",
      "Epoch 206/300 - train_loss: 0.275823 - train_acc: 81.71%\n",
      "Epoch 207/300 - train_loss: 0.271540 - train_acc: 82.57%\n",
      "Epoch 208/300 - train_loss: 0.268166 - train_acc: 82.71%\n",
      "Epoch 209/300 - train_loss: 0.264982 - train_acc: 82.43%\n",
      "Epoch 210/300 - train_loss: 0.266858 - train_acc: 82.57%\n",
      "Epoch 211/300 - train_loss: 0.274118 - train_acc: 81.86%\n",
      "Epoch 212/300 - train_loss: 0.274659 - train_acc: 81.57%\n",
      "Epoch 213/300 - train_loss: 0.268007 - train_acc: 82.86%\n",
      "Epoch 214/300 - train_loss: 0.270601 - train_acc: 82.29%\n",
      "Epoch 215/300 - train_loss: 0.264636 - train_acc: 82.14%\n",
      "Epoch 216/300 - train_loss: 0.277139 - train_acc: 81.86%\n",
      "Epoch 217/300 - train_loss: 0.263574 - train_acc: 82.71%\n",
      "Epoch 218/300 - train_loss: 0.270890 - train_acc: 82.43%\n",
      "Epoch 219/300 - train_loss: 0.266436 - train_acc: 82.43%\n",
      "Epoch 220/300 - train_loss: 0.266160 - train_acc: 82.43%\n",
      "Epoch 221/300 - train_loss: 0.263692 - train_acc: 83.00%\n",
      "Epoch 222/300 - train_loss: 0.266585 - train_acc: 82.43%\n",
      "Epoch 223/300 - train_loss: 0.262326 - train_acc: 82.57%\n",
      "Epoch 224/300 - train_loss: 0.258976 - train_acc: 83.00%\n",
      "Epoch 225/300 - train_loss: 0.257776 - train_acc: 82.43%\n",
      "Epoch 226/300 - train_loss: 0.255632 - train_acc: 82.86%\n",
      "Epoch 227/300 - train_loss: 0.257525 - train_acc: 82.57%\n",
      "Epoch 228/300 - train_loss: 0.263773 - train_acc: 82.71%\n",
      "Epoch 229/300 - train_loss: 0.252880 - train_acc: 82.86%\n",
      "Epoch 230/300 - train_loss: 0.257257 - train_acc: 83.14%\n",
      "Epoch 231/300 - train_loss: 0.259212 - train_acc: 82.71%\n",
      "Epoch 232/300 - train_loss: 0.258012 - train_acc: 82.86%\n",
      "Epoch 233/300 - train_loss: 0.258781 - train_acc: 82.43%\n",
      "Epoch 234/300 - train_loss: 0.254922 - train_acc: 82.57%\n",
      "Epoch 235/300 - train_loss: 0.251967 - train_acc: 82.86%\n",
      "Epoch 236/300 - train_loss: 0.255371 - train_acc: 83.14%\n",
      "Epoch 237/300 - train_loss: 0.254435 - train_acc: 82.71%\n",
      "Epoch 238/300 - train_loss: 0.254156 - train_acc: 82.57%\n",
      "Epoch 239/300 - train_loss: 0.250407 - train_acc: 82.86%\n",
      "Epoch 240/300 - train_loss: 0.255429 - train_acc: 82.71%\n",
      "Epoch 241/300 - train_loss: 0.250599 - train_acc: 83.14%\n",
      "Epoch 242/300 - train_loss: 0.250449 - train_acc: 83.00%\n",
      "Epoch 243/300 - train_loss: 0.251909 - train_acc: 83.43%\n",
      "Epoch 244/300 - train_loss: 0.249972 - train_acc: 83.14%\n",
      "Epoch 245/300 - train_loss: 0.245893 - train_acc: 83.57%\n",
      "Epoch 246/300 - train_loss: 0.253078 - train_acc: 83.71%\n",
      "Epoch 247/300 - train_loss: 0.252045 - train_acc: 83.00%\n",
      "Epoch 248/300 - train_loss: 0.257786 - train_acc: 83.14%\n",
      "Epoch 249/300 - train_loss: 0.253416 - train_acc: 82.57%\n",
      "Epoch 250/300 - train_loss: 0.503446 - train_acc: 80.14%\n",
      "Epoch 251/300 - train_loss: 0.482327 - train_acc: 78.57%\n",
      "Epoch 252/300 - train_loss: 0.434793 - train_acc: 78.71%\n",
      "Epoch 253/300 - train_loss: 0.410012 - train_acc: 77.86%\n",
      "Epoch 254/300 - train_loss: 0.374796 - train_acc: 78.29%\n",
      "Epoch 255/300 - train_loss: 0.355821 - train_acc: 78.57%\n",
      "Epoch 256/300 - train_loss: 0.326684 - train_acc: 80.00%\n",
      "Epoch 257/300 - train_loss: 0.309417 - train_acc: 80.86%\n",
      "Epoch 258/300 - train_loss: 0.301045 - train_acc: 81.57%\n",
      "Epoch 259/300 - train_loss: 0.283645 - train_acc: 82.43%\n",
      "Epoch 260/300 - train_loss: 0.283064 - train_acc: 81.86%\n",
      "Epoch 261/300 - train_loss: 0.275214 - train_acc: 82.29%\n",
      "Epoch 262/300 - train_loss: 0.270526 - train_acc: 82.14%\n",
      "Epoch 263/300 - train_loss: 0.270378 - train_acc: 82.57%\n",
      "Epoch 264/300 - train_loss: 0.267058 - train_acc: 82.71%\n",
      "Epoch 265/300 - train_loss: 0.263720 - train_acc: 82.71%\n",
      "Epoch 266/300 - train_loss: 0.259398 - train_acc: 82.71%\n",
      "Epoch 267/300 - train_loss: 0.268339 - train_acc: 82.43%\n",
      "Epoch 268/300 - train_loss: 0.258457 - train_acc: 83.00%\n",
      "Epoch 269/300 - train_loss: 0.260161 - train_acc: 83.00%\n",
      "Epoch 270/300 - train_loss: 0.260163 - train_acc: 82.71%\n",
      "Epoch 271/300 - train_loss: 0.256438 - train_acc: 83.29%\n",
      "Epoch 272/300 - train_loss: 0.260114 - train_acc: 83.00%\n",
      "Epoch 273/300 - train_loss: 0.265906 - train_acc: 82.57%\n",
      "Epoch 274/300 - train_loss: 0.258658 - train_acc: 83.14%\n",
      "Epoch 275/300 - train_loss: 0.257843 - train_acc: 82.71%\n",
      "Epoch 276/300 - train_loss: 0.255799 - train_acc: 83.14%\n",
      "Epoch 277/300 - train_loss: 0.254623 - train_acc: 82.86%\n",
      "Epoch 278/300 - train_loss: 0.250463 - train_acc: 83.43%\n",
      "Epoch 279/300 - train_loss: 0.249915 - train_acc: 83.43%\n",
      "Epoch 280/300 - train_loss: 0.248483 - train_acc: 83.29%\n",
      "Epoch 281/300 - train_loss: 0.248761 - train_acc: 83.29%\n",
      "Epoch 282/300 - train_loss: 0.256081 - train_acc: 83.29%\n",
      "Epoch 283/300 - train_loss: 0.249816 - train_acc: 83.29%\n",
      "Epoch 284/300 - train_loss: 0.252017 - train_acc: 83.00%\n",
      "Epoch 285/300 - train_loss: 0.252920 - train_acc: 82.86%\n",
      "Epoch 286/300 - train_loss: 0.253390 - train_acc: 83.14%\n",
      "Epoch 287/300 - train_loss: 0.247007 - train_acc: 83.43%\n",
      "Epoch 288/300 - train_loss: 0.250562 - train_acc: 83.86%\n",
      "Epoch 289/300 - train_loss: 0.249840 - train_acc: 83.14%\n",
      "Epoch 290/300 - train_loss: 0.250461 - train_acc: 83.14%\n",
      "Epoch 291/300 - train_loss: 0.245876 - train_acc: 83.43%\n",
      "Epoch 292/300 - train_loss: 0.245005 - train_acc: 83.57%\n",
      "Epoch 293/300 - train_loss: 0.250108 - train_acc: 83.14%\n",
      "Epoch 294/300 - train_loss: 0.248686 - train_acc: 83.14%\n",
      "Epoch 295/300 - train_loss: 0.249461 - train_acc: 83.43%\n",
      "Epoch 296/300 - train_loss: 0.245999 - train_acc: 83.14%\n",
      "Epoch 297/300 - train_loss: 0.249730 - train_acc: 83.00%\n",
      "Epoch 298/300 - train_loss: 0.251851 - train_acc: 83.14%\n",
      "Epoch 299/300 - train_loss: 0.245882 - train_acc: 83.29%\n",
      "Epoch 300/300 - train_loss: 0.247889 - train_acc: 82.86%\n"
     ]
    }
   ],
   "source": [
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HcdROfn39H1m",
    "outputId": "5719ee5b-c3a8-4955-e1d9-7b7c6fb30c91",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss:4.305449 | test_acc:68.57 | auc:0.68\n"
     ]
    }
   ],
   "source": [
    "    loss, accuracy, auc = trainer.test()\n",
    "    print('test_loss:%.6f | test_acc:%.2f | auc:%.2f' % (loss, accuracy, auc))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "gcn_link_prediction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "019bfd6e6d68453ab8302e32ff4c693e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "0e7ae792d1264c1db57e178901615630": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8b3f14adca0e4d919011a7cae002d3fd",
      "placeholder": "​",
      "style": "IPY_MODEL_52dda8a6eec84634acb241491d4b8e71",
      "value": " 1224/1224 [00:06&lt;00:00, 195.28it/s]"
     }
    },
    "52dda8a6eec84634acb241491d4b8e71": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8b3f14adca0e4d919011a7cae002d3fd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a2ec94874bad43b0a297e6e368641ce8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b7db93717d7643e4bf0777503d87cab2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "de30f42132da46f082cee8dfcf051c2f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Computing transition probabilities: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a2ec94874bad43b0a297e6e368641ce8",
      "max": 1224,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_019bfd6e6d68453ab8302e32ff4c693e",
      "value": 1224
     }
    },
    "f152c8a5153c4235bd37d9d47cf48830": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_de30f42132da46f082cee8dfcf051c2f",
       "IPY_MODEL_0e7ae792d1264c1db57e178901615630"
      ],
      "layout": "IPY_MODEL_b7db93717d7643e4bf0777503d87cab2"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
