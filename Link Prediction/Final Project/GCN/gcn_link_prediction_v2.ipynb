{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6rt4c6QLyCDC"
   },
   "source": [
    "## Import Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "4ZxYZNY2yAJV"
   },
   "outputs": [],
   "source": [
    "# Base\n",
    "from time import time\n",
    "from datetime import timedelta\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Graph\n",
    "import networkx as nx\n",
    "# node embedding\n",
    "from node2vec import Node2Vec\n",
    "# sklearn measure\n",
    "from sklearn import metrics\n",
    "\n",
    "# Pytorch\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import init\n",
    "from torch.optim import Adam\n",
    "from torch.optim import SGD\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "9p5HjCc05FxF"
   },
   "outputs": [],
   "source": [
    "class GraphStructure():   \n",
    "    def __init__(self, G):\n",
    "          self.G = G\n",
    "\n",
    "    '''calucate disconnected pairs for negative sample'''\n",
    "    def disconnected_node_pairs(self, node_list):\n",
    "        possible_node_pairs = list()\n",
    "        adjacency_matrix = nx.to_numpy_array(self.G, nodelist=node_list)\n",
    "        for i in range(adjacency_matrix.shape[0]):\n",
    "            for j in range(adjacency_matrix.shape[1]):\n",
    "                if i != j:\n",
    "                    try:\n",
    "                        n = nx.shortest_path_length(G, str(i), str(j))\n",
    "                    except:\n",
    "                        n = 0\n",
    "                    if n <= 2 and adjacency_matrix[i, j] == 0:\n",
    "                        possible_node_pairs.append((node_list[i], node_list[j]))\n",
    "#                 if i != j and adjacency_matrix[i][j] == 0:\n",
    "#                     possible_node_pairs.append((node_list[i], node_list[j]))\n",
    "        return possible_node_pairs\n",
    "\n",
    "    '''calucate removable pairs for positive sample'''\n",
    "    def removable_node_pairs(self, node_pairs_df):\n",
    "        # check whether removing a node pair will cause\n",
    "        # 1: graphic segmentation\n",
    "        # 2: reduce the number of nodes\n",
    "        removable_links_index = list()\n",
    "        original_node_num = self.G.number_of_nodes()\n",
    "        temp_node_pairs_df = node_pairs_df.copy()\n",
    "        for i in tqdm(node_pairs_df.index.values):\n",
    "            temp_G = nx.from_pandas_edgelist(temp_node_pairs_df.drop(index = i), \"node1\", \"node2\", create_using=nx.Graph())\n",
    "            if (nx.number_connected_components(temp_G) == 1) and (temp_G.number_of_nodes() == original_node_num):\n",
    "                removable_links_index.append(i)\n",
    "                temp_node_pairs_df = temp_node_pairs_df.drop(index = i) \n",
    "        return removable_links_index\n",
    "\n",
    "def load_dataset(file_path, split_symbol, read_title=False):\n",
    "    node_pairs = list()\n",
    "    with open(file_path, 'r') as f:\n",
    "        if read_title:\n",
    "            title = f.readline()\n",
    "        for line in f.readlines():\n",
    "            node_pairs.append(list(line.strip().split(split_symbol)))\n",
    "        dataset_df = pd.DataFrame(node_pairs, columns=['node1', 'node2'])\n",
    "    return dataset_df\n",
    "\n",
    "def preprocess(node_pairs_df):\n",
    "    instances = list()\n",
    "    for i, row in node_pairs_df.iterrows():\n",
    "        s_index, t_index, label = row\n",
    "        instance = {\n",
    "            'source': torch.LongTensor(np.array([int(s_index)-1])),\n",
    "            'target': torch.LongTensor(np.array([int(t_index)-1])),\n",
    "            'label': torch.FloatTensor(np.array([float(label)]))\n",
    "        }\n",
    "        instances.append(instance)\n",
    "    return instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dzsk_iJRnJMK"
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "-5RAaK_30bWj"
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Random seed\n",
    "    seed = 42\n",
    "    test_sample_ratio = 0.2\n",
    "    sample_rate = 1\n",
    "    random.seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "    node_pairs_df = load_dataset('out.dimacs10-polblogs', split_symbol='\\t', read_title=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UnO26buXBQaQ"
   },
   "source": [
    "## Dataset Splitting and Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CmBPi_4T5FxI",
    "outputId": "5b8abfc7-632f-4210-f2f3-7331b38c1d3c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total # of nodes: 1224\n",
      "total # of edges: 16715\n"
     ]
    }
   ],
   "source": [
    "    # node_pairs = [ pair for pair in zip(node_pairs_df['node1'], node_pairs_df['node2'])]\n",
    "    last_snapshot = nx.from_pandas_edgelist(node_pairs_df, 'node1', 'node2', create_using=nx.Graph())\n",
    "    last_node_pairs_df = pd.DataFrame(list(last_snapshot.edges()), columns=['node1', 'node2']) \n",
    "    print('total # of nodes:', last_snapshot.number_of_nodes())\n",
    "    print('total # of edges:', last_snapshot.number_of_edges())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pu-Rwyp45FxJ"
   },
   "source": [
    "#### Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1J4VAENIKlyJ",
    "outputId": "7842c941-e28e-4e41-dd36-4a7703562c76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test # of negative: 1463522\t# of positive: 3343\n",
      "sample after:\n",
      "# of negative: 3343\t# of positive: 3343\n",
      "\n",
      "       node1 node2  label\n",
      "625885   730   683      0\n",
      "52829     48   971      0\n",
      "508275   552  1118      0\n",
      "779274   920   690      0\n",
      "262725   237   410      0\n",
      "...      ...   ...    ...\n",
      "16710   1091  1161      1\n",
      "16711   1117  1157      1\n",
      "16712   1168  1210      1\n",
      "16713   1180  1181      1\n",
      "16714   1189  1213      1\n",
      "\n",
      "[6686 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "    # Top 20% edges for test positive sample\n",
    "    test_positive_num = int(last_snapshot.number_of_edges()*test_sample_ratio)\n",
    "    test_positive_df = last_node_pairs_df.tail(test_positive_num).copy()\n",
    "    \n",
    "    # calculate unlink node pairs for test negative sample\n",
    "    test_gs = GraphStructure(last_snapshot)\n",
    "    test_no_edge_pairs = test_gs.disconnected_node_pairs(list(dict.fromkeys(last_node_pairs_df['node1'].to_list()+last_node_pairs_df['node2'].to_list())))\n",
    "    test_no_edge_pairs_df = pd.DataFrame(test_no_edge_pairs, columns=['node1', 'node2'])\n",
    "    test_negative_df = test_no_edge_pairs_df\n",
    "    \n",
    "    # labeling\n",
    "    test_negative_df['label'] = 0\n",
    "    test_positive_df['label'] = 1\n",
    "    print(\"test # of negative: %d\\t# of positive: %d\" % (len(test_negative_df), len(test_positive_df)))\n",
    "    \n",
    "    test_negative_df = test_negative_df.sample(int(len(test_positive_df)*sample_rate), replace=True)\n",
    "    test_dataset_df = test_negative_df.append(test_positive_df)\n",
    "    test_negative_num, test_positive_num = test_dataset_df.label.value_counts()\n",
    "    print(\"sample after:\\n# of negative: %d\\t# of positive: %d\\n\" % (test_positive_num, test_negative_num))\n",
    "    print(test_dataset_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BOOEWqlG5FxL"
   },
   "source": [
    "#### Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qLET0xn8R_qa",
    "outputId": "612bf868-3819-450e-c99d-34c4558b2cdf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of negative: 270896\t# of positive: 3343\n",
      "sample after:\n",
      "# of negative: 3343\t# of positive: 3343\n",
      "\n",
      "       node1 node2  label\n",
      "157913  1022  1052      0\n",
      "242007   863   901      0\n",
      "55185    698   654      0\n",
      "232816  1179   601      0\n",
      "186429  1002   992      0\n",
      "...      ...   ...    ...\n",
      "16710   1091  1161      1\n",
      "16711   1117  1157      1\n",
      "16712   1168  1210      1\n",
      "16713   1180  1181      1\n",
      "16714   1189  1213      1\n",
      "\n",
      "[6686 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "    # Top 80% edges for train positive edge\n",
    "    train_positive_num = last_snapshot.number_of_edges()-test_positive_num\n",
    "    train_positive_df = test_positive_df.head(train_positive_num).copy()\n",
    "    train_snapshot = nx.from_pandas_edgelist(train_positive_df, 'node1', 'node2', create_using=nx.Graph())\n",
    "    \n",
    "    # remove edges with test positive sample for training snapshot\n",
    "    train_snapshot = last_snapshot.copy()\n",
    "    for pair in zip(test_positive_df['node1'], test_positive_df['node2']):\n",
    "        train_snapshot.remove_edge(*pair)\n",
    "    \n",
    "    # calculate unlink node pairs for train negative sample\n",
    "    train_gs = GraphStructure(train_snapshot)\n",
    "    train_no_edge_pairs = train_gs.disconnected_node_pairs(list(dict.fromkeys(train_positive_df['node1'].to_list()+train_positive_df['node2'].to_list())))\n",
    "    train_no_edge_pairs_df = pd.DataFrame(train_no_edge_pairs, columns=['node1', 'node2'])\n",
    "    train_negative_df = train_no_edge_pairs_df\n",
    "    \n",
    "    # labeling\n",
    "    train_negative_df['label'] = 0\n",
    "    train_positive_df['label'] = 1\n",
    "    print(\"# of negative: %d\\t# of positive: %d\" % (len(train_negative_df), len(train_positive_df)))\n",
    "\n",
    "    train_negative_df = train_negative_df.sample(len(train_positive_df), replace=True)\n",
    "    train_dataset_df = train_negative_df.append(train_positive_df)\n",
    "    train_positive_num, train_negative_num = train_dataset_df.label.value_counts()\n",
    "    print(\"sample after:\\n# of negative: %d\\t# of positive: %d\\n\" % (train_positive_num, train_negative_num))\n",
    "    print(train_dataset_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T890E3P55FxM"
   },
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "geVaSGGd5FxM",
    "outputId": "254e62c6-7af6-4dd2-bb3a-7818d7b2ddc3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of test instances: 6686\n",
      "# of train instances: 6686\n",
      "# of total instances: 13372\n"
     ]
    }
   ],
   "source": [
    "    test_instances = preprocess(test_dataset_df)\n",
    "    train_instances = preprocess(train_dataset_df)\n",
    "    \n",
    "    print('# of test instances:', len(test_instances))\n",
    "    print('# of train instances:', len(train_instances))\n",
    "    print('# of total instances:', (len(train_instances)+len(test_instances)))\n",
    "#     test_instances = preprocess(test_dataset_df)\n",
    "#     valid_instances = preprocess(valid_dataset_df)\n",
    "#     train_instances = preprocess(train_dataset_df)\n",
    "    \n",
    "#     print('# of test instances:', len(test_instances))\n",
    "#     print('# of valid instances:', len(valid_stances))\n",
    "#     print('# of train instances:', len(train_instances))\n",
    "#     print('# of total instances:', (len(train_instances)+len(valid_instances)+len(test_instances)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7rTSUoWMOmeZ"
   },
   "source": [
    "## Graph Node Embedding with Node2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 83,
     "referenced_widgets": [
      "f152c8a5153c4235bd37d9d47cf48830",
      "b7db93717d7643e4bf0777503d87cab2",
      "de30f42132da46f082cee8dfcf051c2f",
      "0e7ae792d1264c1db57e178901615630",
      "019bfd6e6d68453ab8302e32ff4c693e",
      "a2ec94874bad43b0a297e6e368641ce8",
      "52dda8a6eec84634acb241491d4b8e71",
      "8b3f14adca0e4d919011a7cae002d3fd"
     ]
    },
    "id": "K-91l9ElOnDw",
    "outputId": "0cd5aabe-f6b4-491e-e1d4-1916bfbcf847",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88a00f18c03849cea0b4aa2edc8b4cb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Computing transition probabilities'), FloatProgress(value=0.0, max=1224.0), HTML(va…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1):   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1): 100%|██████████| 10/10 [00:36<00:00,  3.70s/it]\n"
     ]
    }
   ],
   "source": [
    "    node2vec = Node2Vec(train_snapshot, dimensions=128, walk_length=80, num_walks=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "bqsoVI4PtZXY"
   },
   "outputs": [],
   "source": [
    "    n2v_model = node2vec.fit(window=10, min_count=1, batch_words=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E1A7aBo65FxN",
    "outputId": "7e122291-2177-4c35-9796-d90e8f6e95e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1224, 128)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    node_embedding = n2v_model.wv.vectors\n",
    "    node_embedding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "frU6f-Z45FxO"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Dm4wkWxc5FxO"
   },
   "outputs": [],
   "source": [
    "    class NodePairDataset(Dataset):\n",
    "        def __init__(self, instances):\n",
    "            self.instances = instances\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.instances)\n",
    "\n",
    "        def __getitem__(self, i):\n",
    "            instance = self.instances[i]\n",
    "            source = instance['source']\n",
    "            target = instance['target']\n",
    "            label = instance['label']\n",
    "            return source, target, label\n",
    "        \n",
    "    def collate_fn(batch):\n",
    "        source, target, labels = zip(*batch)\n",
    "        source = torch.stack(source)\n",
    "        target = torch.stack(target)\n",
    "        labels = torch.stack(labels)\n",
    "        return source, target, labels\n",
    "\n",
    "    def get_dataloader(instances, collate_fn=collate_fn,batch_size=1, num_workers=2):\n",
    "        dataset = NodePairDataset(instances)\n",
    "        dataloader = DataLoader(dataset, collate_fn=collate_fn, shuffle=True, batch_size=batch_size, num_workers=num_workers)\n",
    "        return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "bg6RaO_85FxO"
   },
   "outputs": [],
   "source": [
    "    class LinkEmbedding(nn.Module):\n",
    "        def __init__(self, inputs_dim, output_dim):\n",
    "            super(LinkEmbedding, self).__init__()\n",
    "            self.weight = nn.Parameter(nn.init.xavier_uniform_(torch.empty(inputs_dim, output_dim)))\n",
    "            \n",
    "            \n",
    "        def forward(self, hidden_state, source, target):\n",
    "            propagation = torch.mul(hidden_state[source, :], hidden_state[target, :])\n",
    "            propagation = propagation.matmul(self.weight)\n",
    "            return propagation\n",
    "    \n",
    "    class GraphConvolution(nn.Module):\n",
    "        def __init__(self, inputs_dim, hidden_dim):\n",
    "            super(GraphConvolution, self).__init__()\n",
    "            self.weight = nn.Parameter(nn.init.kaiming_normal_(torch.empty(inputs_dim, hidden_dim), mode='fan_in', nonlinearity='relu'))\n",
    "            # self.weight = nn.Parameter(nn.init.xavier_uniform_(torch.empty(inputs_dim, hidden_dim)))\n",
    "            \n",
    "            \n",
    "        def forward(self, input_features, adj_matrix):\n",
    "            # aggregate \n",
    "            aggregate  = torch.mm(input_features, self.weight)\n",
    "            propagation = torch.mm(adj_matrix, aggregate)\n",
    "            return propagation\n",
    "        \n",
    "    class GCN(nn.Module):\n",
    "        def __init__(self, inputs_dim, hidden_dim, output_dim):\n",
    "            super(GCN, self).__init__()\n",
    "            self.gcn_layer1 = GraphConvolution(inputs_dim, hidden_dim)\n",
    "            self.gcn_layer2 = GraphConvolution(hidden_dim, hidden_dim)\n",
    "            self.link_embed_layer = LinkEmbedding(hidden_dim, output_dim)\n",
    "            self.relu = nn.ReLU()\n",
    "            self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        def forward(self, input_features, adj_matrix, source, target):\n",
    "            hidden_state = self.relu(self.gcn_layer1(input_features, adj_matrix))\n",
    "            hidden_state = self.gcn_layer2(hidden_state, adj_matrix)\n",
    "            hidden_state = self.link_embed_layer(hidden_state, source, target)\n",
    "            return hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "2IAyLfi25FxO"
   },
   "outputs": [],
   "source": [
    "    class GCNTrainer():\n",
    "        def __init__(self, features, adj_matrix, train_instances, valid_instances=None, test_instances=None, \n",
    "            hidden_dim=16, epoch=1, max_patience=0, learning_rate=1e-2, batch_size=1,num_workers=2, valid=False):\n",
    "\n",
    "            # parameters\n",
    "            self.valid = valid\n",
    "            self.epochs = epoch\n",
    "            self.learning_rate = learning_rate\n",
    "            self.batch_size = batch_size\n",
    "            self.num_workers = num_workers\n",
    "            # early stop\n",
    "            self.best_valid_loss = 1e10\n",
    "            self.max_patience = max_patience\n",
    "            self.patience = 0\n",
    "\n",
    "            # setup cuda device\n",
    "            self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "            # dataset\n",
    "            self.train_instances = train_instances\n",
    "            self.valid_instances = valid_instances\n",
    "            self.test_instances = test_instances\n",
    "            self.features = torch.FloatTensor(features).cuda()\n",
    "            self.adj_matrix = torch.FloatTensor(self.normalize(adj_matrix)).cuda()\n",
    "            \n",
    "            # GCN Model\n",
    "            self.model = GCN(self.features.shape[1], hidden_dim, output_dim=1)\n",
    "            self.model.cuda()\n",
    "            # print(self.model)\n",
    "\n",
    "            # Adam optimizer with hyper-parameter\n",
    "            # self.optimizer = SGD(self.model.parameters(), lr=self.learning_rate)\n",
    "            self.optimizer = Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "\n",
    "            # Binary Cross Entropy with Loss for criterion\n",
    "            self.criterion = nn.BCEWithLogitsLoss()\n",
    "        \n",
    "\n",
    "        def normalize(self, A):\n",
    "            '''\n",
    "            :var I: identity matrix\n",
    "            :var A: adjacency matrix\n",
    "            :var D: degree matrix\n",
    "            :var A_hat: adding self-loops\n",
    "            :var D_inv: degree inverse matrix\n",
    "            '''\n",
    "            I = np.matrix(np.identity(A.shape[0]))\n",
    "            A_hat = I + A\n",
    "            \n",
    "            D = np.array(np.sum(A, axis=0))\n",
    "            D_inv = D**-0.5\n",
    "            D_inv[np.isinf(D_inv)] = 0.\n",
    "            D_inv = np.diag(D_inv)\n",
    "\n",
    "            A_hat = D_inv * A_hat * D_inv\n",
    "            return A_hat\n",
    "        \n",
    "        def accuracy(self, predicts, labels):\n",
    "            predicts_labels = torch.round(torch.sigmoid(predicts))\n",
    "            total_correct = (predicts_labels == labels).sum().float()\n",
    "            return torch.round((total_correct / labels.shape[0]) * 100)\n",
    "\n",
    "        def train(self):\n",
    "            start_time = time()\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            train_dataloader = get_dataloader(self.train_instances, collate_fn=collate_fn, batch_size=self.batch_size, num_workers=self.num_workers)\n",
    "            for epoch in range(self.epochs):\n",
    "                self.model.train()\n",
    "                epoch_loss, epoch_acc = 0, 0\n",
    "                ''' train '''\n",
    "                for i, batch in enumerate(train_dataloader, start=1):\n",
    "                    batch = (tensor.cuda() for tensor in batch)\n",
    "                    source, target, labels = batch\n",
    "                    # forward\n",
    "                    # feature: all node embedding\n",
    "                    outputs = self.model(self.features, self.adj_matrix, source, target)\n",
    "                    outputs = outputs.reshape(labels.size())\n",
    "                    # backward\n",
    "                    loss = self.criterion(outputs, labels)\n",
    "                    acc = self.accuracy(outputs, labels)\n",
    "                    epoch_loss += loss.item()\n",
    "                    epoch_acc += acc\n",
    "                    \n",
    "                    loss.backward()\n",
    "                    # optimize\n",
    "                    self.optimizer.step()\n",
    "                    self.optimizer.zero_grad()\n",
    "                    \n",
    "                    # Progressbar\n",
    "                    elapsed_time = time() - start_time\n",
    "                    elapsed_time = timedelta(seconds=int(elapsed_time))\n",
    "                    # print(\"Epoch %d/%d | loss: %.6f | acc: %f | batch: [%d/%d] | %s\" % (epoch+1, self.epochs, loss, acc, i, len(train_dataloader), elapsed_time))\n",
    "                \n",
    "                print(\"Epoch %d/%d - train_loss: %.6f - train_acc: %.2f%%\" \n",
    "                      % (epoch+1, self.epochs, epoch_loss/len(train_dataloader), epoch_acc/len(train_dataloader)))\n",
    "                \n",
    "                ''' validate '''\n",
    "                if self.valid:\n",
    "                    valid_loss, valid_acc = self.validate()\n",
    "                    elapsed_time = time() - start_time\n",
    "                    elapsed_time = timedelta(seconds=int(elapsed_time))\n",
    "                    print(\"Epoch %d/%d - valid_loss: %.6f - valid_acc: %.2f%%\" % (epoch+1, self.epochs, valid_loss, valid_acc))\n",
    "\n",
    "                    # early stoping\n",
    "                    if valid_loss < self.best_valid_loss:\n",
    "                        self.patience = 0\n",
    "                        self.best_valid_loss = valid_loss\n",
    "                    else:\n",
    "                        self.patience += 1\n",
    "\n",
    "                    if self.patience > self.max_patience:\n",
    "                        print('Earlystop at epoch %d' % (epoch+1))\n",
    "                        break\n",
    "\n",
    "\n",
    "        def validate(self):\n",
    "            total_loss, total_acc = 0, 0\n",
    "            self.model.eval()\n",
    "            with torch.no_grad():\n",
    "                valid_dataloader = get_dataloader(self.valid_instances, collate_fn=collate_fn, batch_size=self.batch_size, num_workers=self.num_workers)\n",
    "                for batch in valid_dataloader:\n",
    "                    batch = (tensor.cuda() for tensor in batch)\n",
    "                    source, target, labels = batch\n",
    "                    outputs = self.model(self.features, self.adj_matrix, source, target)\n",
    "                    outputs = outputs.reshape(labels.size())\n",
    "                    loss = self.criterion(outputs, labels)\n",
    "                    # loss and accuracy\n",
    "                    total_loss += loss.item()\n",
    "                    total_acc += self.accuracy(outputs, labels)\n",
    "            \n",
    "            total_loss /= len(valid_dataloader)\n",
    "            total_acc /= len(valid_dataloader)\n",
    "            return float(total_loss), float(total_acc)\n",
    "\n",
    "        def test(self):\n",
    "            total_loss, total_acc, auc = 0, 0, 0\n",
    "            total_predicts, total_labels = list(), list()\n",
    "            self.model.eval()\n",
    "            with torch.no_grad():\n",
    "                test_dataloader = get_dataloader(self.test_instances, collate_fn=collate_fn, batch_size=self.batch_size, num_workers=self.num_workers)\n",
    "                for batch in test_dataloader:\n",
    "                    batch = (tensor.cuda() for tensor in batch)\n",
    "                    source, target, labels = batch\n",
    "                    outputs = self.model(self.features, self.adj_matrix, source, target)\n",
    "                    outputs = outputs.reshape(labels.size())\n",
    "                    # auc\n",
    "                    total_predicts += torch.round(torch.sigmoid(outputs.cpu())).squeeze().numpy().tolist()\n",
    "                    total_labels += torch.round(torch.sigmoid(labels.cpu())).squeeze().numpy().tolist()\n",
    "                    loss = self.criterion(outputs, labels)\n",
    "                    # loss and accuracy\n",
    "                    total_loss += loss.item()\n",
    "                    total_acc += self.accuracy(outputs, labels)\n",
    "            \n",
    "            total_loss /= len(test_dataloader)\n",
    "            total_acc /= len(test_dataloader)\n",
    "            \n",
    "            fpr, tpr, thresholds = metrics.roc_curve(total_labels, total_predicts, pos_label=1)\n",
    "            auc = metrics.auc(fpr, tpr)\n",
    "            return float(total_loss), float(total_acc), auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oTS4-KQH5FxP",
    "outputId": "c4fc3b90-f503-4301-a524-09298c72c4e8",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 1. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "    adj_matrix = nx.to_numpy_array(train_snapshot)\n",
    "    print(adj_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O_FrH6kq5FxP",
    "outputId": "844b1e6b-2a5e-42a3-c554-c26135d2266f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-1386f989da06>:51: RuntimeWarning: divide by zero encountered in power\n",
      "  D_inv = D**-0.5\n"
     ]
    }
   ],
   "source": [
    "    trainer = GCNTrainer(features=node_embedding, adj_matrix=adj_matrix, \n",
    "                         train_instances=train_instances, \n",
    "                         valid_instances=None,\n",
    "                         test_instances=test_instances,\n",
    "                         hidden_dim=64, epoch=300,learning_rate=1e-2, batch_size=128, num_workers=2, valid=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4thQlWPX38zg",
    "outputId": "e0c37871-cbe3-44cc-cabc-24b47d3f4c7e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300 - train_loss: 0.626102 - train_acc: 66.53%\n",
      "Epoch 2/300 - train_loss: 0.594485 - train_acc: 70.17%\n",
      "Epoch 3/300 - train_loss: 0.581883 - train_acc: 71.87%\n",
      "Epoch 4/300 - train_loss: 0.566181 - train_acc: 73.36%\n",
      "Epoch 5/300 - train_loss: 0.570826 - train_acc: 73.36%\n",
      "Epoch 6/300 - train_loss: 0.555804 - train_acc: 74.47%\n",
      "Epoch 7/300 - train_loss: 0.549480 - train_acc: 75.45%\n",
      "Epoch 8/300 - train_loss: 0.530423 - train_acc: 76.36%\n",
      "Epoch 9/300 - train_loss: 0.531790 - train_acc: 76.53%\n",
      "Epoch 10/300 - train_loss: 0.533649 - train_acc: 75.91%\n",
      "Epoch 11/300 - train_loss: 0.519522 - train_acc: 76.96%\n",
      "Epoch 12/300 - train_loss: 0.514288 - train_acc: 77.09%\n",
      "Epoch 13/300 - train_loss: 0.507169 - train_acc: 77.79%\n",
      "Epoch 14/300 - train_loss: 0.506887 - train_acc: 77.75%\n",
      "Epoch 15/300 - train_loss: 0.502697 - train_acc: 78.28%\n",
      "Epoch 16/300 - train_loss: 0.496955 - train_acc: 78.77%\n",
      "Epoch 17/300 - train_loss: 0.502138 - train_acc: 78.30%\n",
      "Epoch 18/300 - train_loss: 0.498549 - train_acc: 78.98%\n",
      "Epoch 19/300 - train_loss: 0.489047 - train_acc: 79.51%\n",
      "Epoch 20/300 - train_loss: 0.482738 - train_acc: 79.66%\n",
      "Epoch 21/300 - train_loss: 0.484750 - train_acc: 79.51%\n",
      "Epoch 22/300 - train_loss: 0.481987 - train_acc: 79.43%\n",
      "Epoch 23/300 - train_loss: 0.475746 - train_acc: 79.55%\n",
      "Epoch 24/300 - train_loss: 0.474176 - train_acc: 79.98%\n",
      "Epoch 25/300 - train_loss: 0.467087 - train_acc: 80.08%\n",
      "Epoch 26/300 - train_loss: 0.467853 - train_acc: 80.11%\n",
      "Epoch 27/300 - train_loss: 0.486629 - train_acc: 79.81%\n",
      "Epoch 28/300 - train_loss: 0.479155 - train_acc: 79.47%\n",
      "Epoch 29/300 - train_loss: 0.465819 - train_acc: 79.92%\n",
      "Epoch 30/300 - train_loss: 0.463373 - train_acc: 80.49%\n",
      "Epoch 31/300 - train_loss: 0.464786 - train_acc: 80.51%\n",
      "Epoch 32/300 - train_loss: 0.473256 - train_acc: 80.51%\n",
      "Epoch 33/300 - train_loss: 0.466251 - train_acc: 79.96%\n",
      "Epoch 34/300 - train_loss: 0.478606 - train_acc: 80.04%\n",
      "Epoch 35/300 - train_loss: 0.463292 - train_acc: 80.66%\n",
      "Epoch 36/300 - train_loss: 0.463723 - train_acc: 80.92%\n",
      "Epoch 37/300 - train_loss: 0.451234 - train_acc: 80.89%\n",
      "Epoch 38/300 - train_loss: 0.450852 - train_acc: 81.02%\n",
      "Epoch 39/300 - train_loss: 0.439476 - train_acc: 81.77%\n",
      "Epoch 40/300 - train_loss: 0.469620 - train_acc: 80.62%\n",
      "Epoch 41/300 - train_loss: 0.450781 - train_acc: 81.11%\n",
      "Epoch 42/300 - train_loss: 0.444423 - train_acc: 81.47%\n",
      "Epoch 43/300 - train_loss: 0.445249 - train_acc: 81.23%\n",
      "Epoch 44/300 - train_loss: 0.468932 - train_acc: 81.21%\n",
      "Epoch 45/300 - train_loss: 0.450738 - train_acc: 81.15%\n",
      "Epoch 46/300 - train_loss: 0.443912 - train_acc: 81.60%\n",
      "Epoch 47/300 - train_loss: 0.436806 - train_acc: 82.13%\n",
      "Epoch 48/300 - train_loss: 0.435649 - train_acc: 81.83%\n",
      "Epoch 49/300 - train_loss: 0.431593 - train_acc: 82.13%\n",
      "Epoch 50/300 - train_loss: 0.428328 - train_acc: 82.49%\n",
      "Epoch 51/300 - train_loss: 0.421281 - train_acc: 82.81%\n",
      "Epoch 52/300 - train_loss: 0.421301 - train_acc: 82.74%\n",
      "Epoch 53/300 - train_loss: 0.427946 - train_acc: 82.17%\n",
      "Epoch 54/300 - train_loss: 0.419838 - train_acc: 82.58%\n",
      "Epoch 55/300 - train_loss: 0.434535 - train_acc: 82.42%\n",
      "Epoch 56/300 - train_loss: 0.438884 - train_acc: 81.85%\n",
      "Epoch 57/300 - train_loss: 0.428390 - train_acc: 82.58%\n",
      "Epoch 58/300 - train_loss: 0.415374 - train_acc: 82.89%\n",
      "Epoch 59/300 - train_loss: 0.414852 - train_acc: 83.08%\n",
      "Epoch 60/300 - train_loss: 0.423251 - train_acc: 82.91%\n",
      "Epoch 61/300 - train_loss: 0.427920 - train_acc: 82.60%\n",
      "Epoch 62/300 - train_loss: 0.419766 - train_acc: 82.91%\n",
      "Epoch 63/300 - train_loss: 0.410349 - train_acc: 82.94%\n",
      "Epoch 64/300 - train_loss: 0.417340 - train_acc: 82.75%\n",
      "Epoch 65/300 - train_loss: 0.412272 - train_acc: 83.45%\n",
      "Epoch 66/300 - train_loss: 0.414049 - train_acc: 83.04%\n",
      "Epoch 67/300 - train_loss: 0.397033 - train_acc: 84.00%\n",
      "Epoch 68/300 - train_loss: 0.408917 - train_acc: 83.58%\n",
      "Epoch 69/300 - train_loss: 0.396616 - train_acc: 83.68%\n",
      "Epoch 70/300 - train_loss: 0.400576 - train_acc: 83.68%\n",
      "Epoch 71/300 - train_loss: 0.393154 - train_acc: 84.00%\n",
      "Epoch 72/300 - train_loss: 0.390543 - train_acc: 84.15%\n",
      "Epoch 73/300 - train_loss: 0.393198 - train_acc: 84.58%\n",
      "Epoch 74/300 - train_loss: 0.390357 - train_acc: 84.23%\n",
      "Epoch 75/300 - train_loss: 0.381989 - train_acc: 84.81%\n",
      "Epoch 76/300 - train_loss: 0.385087 - train_acc: 84.45%\n",
      "Epoch 77/300 - train_loss: 0.454571 - train_acc: 82.74%\n",
      "Epoch 78/300 - train_loss: 0.450304 - train_acc: 81.85%\n",
      "Epoch 79/300 - train_loss: 0.430269 - train_acc: 83.34%\n",
      "Epoch 80/300 - train_loss: 0.420735 - train_acc: 83.06%\n",
      "Epoch 81/300 - train_loss: 0.389610 - train_acc: 84.13%\n",
      "Epoch 82/300 - train_loss: 0.390451 - train_acc: 84.36%\n",
      "Epoch 83/300 - train_loss: 0.388156 - train_acc: 84.49%\n",
      "Epoch 84/300 - train_loss: 0.409941 - train_acc: 84.42%\n",
      "Epoch 85/300 - train_loss: 0.388700 - train_acc: 84.60%\n",
      "Epoch 86/300 - train_loss: 0.384050 - train_acc: 84.25%\n",
      "Epoch 87/300 - train_loss: 0.373993 - train_acc: 85.11%\n",
      "Epoch 88/300 - train_loss: 0.381246 - train_acc: 84.89%\n",
      "Epoch 89/300 - train_loss: 0.385104 - train_acc: 84.38%\n",
      "Epoch 90/300 - train_loss: 0.381150 - train_acc: 84.91%\n",
      "Epoch 91/300 - train_loss: 0.368714 - train_acc: 84.85%\n",
      "Epoch 92/300 - train_loss: 0.402689 - train_acc: 84.74%\n",
      "Epoch 93/300 - train_loss: 0.389957 - train_acc: 84.36%\n",
      "Epoch 94/300 - train_loss: 0.374253 - train_acc: 85.19%\n",
      "Epoch 95/300 - train_loss: 0.380178 - train_acc: 85.38%\n",
      "Epoch 96/300 - train_loss: 0.384307 - train_acc: 84.91%\n",
      "Epoch 97/300 - train_loss: 0.367257 - train_acc: 85.43%\n",
      "Epoch 98/300 - train_loss: 0.360475 - train_acc: 85.72%\n",
      "Epoch 99/300 - train_loss: 0.376092 - train_acc: 84.96%\n",
      "Epoch 100/300 - train_loss: 0.360176 - train_acc: 85.64%\n",
      "Epoch 101/300 - train_loss: 0.352547 - train_acc: 85.85%\n",
      "Epoch 102/300 - train_loss: 0.349857 - train_acc: 86.00%\n",
      "Epoch 103/300 - train_loss: 0.351853 - train_acc: 86.11%\n",
      "Epoch 104/300 - train_loss: 0.343160 - train_acc: 86.74%\n",
      "Epoch 105/300 - train_loss: 0.343764 - train_acc: 86.43%\n",
      "Epoch 106/300 - train_loss: 0.349182 - train_acc: 86.21%\n",
      "Epoch 107/300 - train_loss: 0.405880 - train_acc: 85.26%\n",
      "Epoch 108/300 - train_loss: 0.521456 - train_acc: 82.34%\n",
      "Epoch 109/300 - train_loss: 0.472014 - train_acc: 82.89%\n",
      "Epoch 110/300 - train_loss: 0.440438 - train_acc: 82.60%\n",
      "Epoch 111/300 - train_loss: 0.381991 - train_acc: 84.51%\n",
      "Epoch 112/300 - train_loss: 0.366724 - train_acc: 85.74%\n",
      "Epoch 113/300 - train_loss: 0.355830 - train_acc: 86.00%\n",
      "Epoch 114/300 - train_loss: 0.353087 - train_acc: 86.23%\n",
      "Epoch 115/300 - train_loss: 0.352566 - train_acc: 86.36%\n",
      "Epoch 116/300 - train_loss: 0.358510 - train_acc: 86.15%\n",
      "Epoch 117/300 - train_loss: 0.385673 - train_acc: 85.00%\n",
      "Epoch 118/300 - train_loss: 0.375400 - train_acc: 85.79%\n",
      "Epoch 119/300 - train_loss: 0.378390 - train_acc: 85.36%\n",
      "Epoch 120/300 - train_loss: 0.383296 - train_acc: 85.26%\n",
      "Epoch 121/300 - train_loss: 0.353073 - train_acc: 86.21%\n",
      "Epoch 122/300 - train_loss: 0.345986 - train_acc: 86.49%\n",
      "Epoch 123/300 - train_loss: 0.339311 - train_acc: 86.81%\n",
      "Epoch 124/300 - train_loss: 0.329895 - train_acc: 87.30%\n",
      "Epoch 125/300 - train_loss: 0.329578 - train_acc: 87.28%\n",
      "Epoch 126/300 - train_loss: 0.329094 - train_acc: 87.09%\n",
      "Epoch 127/300 - train_loss: 0.330506 - train_acc: 87.19%\n",
      "Epoch 128/300 - train_loss: 0.326976 - train_acc: 87.40%\n",
      "Epoch 129/300 - train_loss: 0.323698 - train_acc: 87.34%\n",
      "Epoch 130/300 - train_loss: 0.331775 - train_acc: 87.25%\n",
      "Epoch 131/300 - train_loss: 0.326737 - train_acc: 87.51%\n",
      "Epoch 132/300 - train_loss: 0.361350 - train_acc: 87.26%\n",
      "Epoch 133/300 - train_loss: 0.416233 - train_acc: 84.47%\n",
      "Epoch 134/300 - train_loss: 0.453785 - train_acc: 84.45%\n",
      "Epoch 135/300 - train_loss: 0.452158 - train_acc: 83.70%\n",
      "Epoch 136/300 - train_loss: 0.400769 - train_acc: 84.85%\n",
      "Epoch 137/300 - train_loss: 0.413204 - train_acc: 85.11%\n",
      "Epoch 138/300 - train_loss: 0.447477 - train_acc: 83.91%\n",
      "Epoch 139/300 - train_loss: 0.386134 - train_acc: 85.45%\n",
      "Epoch 140/300 - train_loss: 0.366243 - train_acc: 85.74%\n",
      "Epoch 141/300 - train_loss: 0.359700 - train_acc: 85.79%\n",
      "Epoch 142/300 - train_loss: 0.368275 - train_acc: 86.15%\n",
      "Epoch 143/300 - train_loss: 0.356122 - train_acc: 86.08%\n",
      "Epoch 144/300 - train_loss: 0.343884 - train_acc: 86.64%\n",
      "Epoch 145/300 - train_loss: 0.337673 - train_acc: 87.00%\n",
      "Epoch 146/300 - train_loss: 0.342124 - train_acc: 86.91%\n",
      "Epoch 147/300 - train_loss: 0.334259 - train_acc: 87.15%\n",
      "Epoch 148/300 - train_loss: 0.336309 - train_acc: 87.47%\n",
      "Epoch 149/300 - train_loss: 0.357824 - train_acc: 86.04%\n",
      "Epoch 150/300 - train_loss: 0.346266 - train_acc: 87.13%\n",
      "Epoch 151/300 - train_loss: 0.330925 - train_acc: 87.21%\n",
      "Epoch 152/300 - train_loss: 0.329904 - train_acc: 87.51%\n",
      "Epoch 153/300 - train_loss: 0.327318 - train_acc: 87.30%\n",
      "Epoch 154/300 - train_loss: 0.316041 - train_acc: 88.09%\n",
      "Epoch 155/300 - train_loss: 0.316722 - train_acc: 87.94%\n",
      "Epoch 156/300 - train_loss: 0.314305 - train_acc: 88.00%\n",
      "Epoch 157/300 - train_loss: 0.317279 - train_acc: 88.19%\n",
      "Epoch 158/300 - train_loss: 0.327725 - train_acc: 87.89%\n",
      "Epoch 159/300 - train_loss: 0.332577 - train_acc: 87.23%\n",
      "Epoch 160/300 - train_loss: 0.318084 - train_acc: 88.19%\n",
      "Epoch 161/300 - train_loss: 0.311689 - train_acc: 88.02%\n",
      "Epoch 162/300 - train_loss: 0.307682 - train_acc: 88.38%\n",
      "Epoch 163/300 - train_loss: 0.305497 - train_acc: 88.57%\n",
      "Epoch 164/300 - train_loss: 0.310981 - train_acc: 88.13%\n",
      "Epoch 165/300 - train_loss: 0.324476 - train_acc: 88.00%\n",
      "Epoch 166/300 - train_loss: 0.441985 - train_acc: 86.28%\n",
      "Epoch 167/300 - train_loss: 0.400326 - train_acc: 85.77%\n",
      "Epoch 168/300 - train_loss: 0.397547 - train_acc: 85.25%\n",
      "Epoch 169/300 - train_loss: 0.354838 - train_acc: 86.53%\n",
      "Epoch 170/300 - train_loss: 0.329100 - train_acc: 87.30%\n",
      "Epoch 171/300 - train_loss: 0.321253 - train_acc: 87.68%\n",
      "Epoch 172/300 - train_loss: 0.340862 - train_acc: 87.15%\n",
      "Epoch 173/300 - train_loss: 0.327795 - train_acc: 87.85%\n",
      "Epoch 174/300 - train_loss: 0.310554 - train_acc: 88.23%\n",
      "Epoch 175/300 - train_loss: 0.314335 - train_acc: 88.04%\n",
      "Epoch 176/300 - train_loss: 0.307554 - train_acc: 88.47%\n",
      "Epoch 177/300 - train_loss: 0.302929 - train_acc: 88.53%\n",
      "Epoch 178/300 - train_loss: 0.299805 - train_acc: 88.91%\n",
      "Epoch 179/300 - train_loss: 0.296505 - train_acc: 88.94%\n",
      "Epoch 180/300 - train_loss: 0.294160 - train_acc: 89.28%\n",
      "Epoch 181/300 - train_loss: 0.294478 - train_acc: 88.91%\n",
      "Epoch 182/300 - train_loss: 0.313408 - train_acc: 88.23%\n",
      "Epoch 183/300 - train_loss: 0.325139 - train_acc: 87.79%\n",
      "Epoch 184/300 - train_loss: 0.355132 - train_acc: 87.04%\n",
      "Epoch 185/300 - train_loss: 0.332129 - train_acc: 87.57%\n",
      "Epoch 186/300 - train_loss: 0.306476 - train_acc: 88.74%\n",
      "Epoch 187/300 - train_loss: 0.295997 - train_acc: 89.04%\n",
      "Epoch 188/300 - train_loss: 0.293320 - train_acc: 88.85%\n",
      "Epoch 189/300 - train_loss: 0.301214 - train_acc: 88.98%\n",
      "Epoch 190/300 - train_loss: 0.333091 - train_acc: 87.81%\n",
      "Epoch 191/300 - train_loss: 0.349258 - train_acc: 87.04%\n",
      "Epoch 192/300 - train_loss: 0.332789 - train_acc: 88.02%\n",
      "Epoch 193/300 - train_loss: 0.317657 - train_acc: 88.40%\n",
      "Epoch 194/300 - train_loss: 0.327629 - train_acc: 87.83%\n",
      "Epoch 195/300 - train_loss: 0.311184 - train_acc: 88.58%\n",
      "Epoch 196/300 - train_loss: 0.297092 - train_acc: 88.87%\n",
      "Epoch 197/300 - train_loss: 0.289878 - train_acc: 89.30%\n",
      "Epoch 198/300 - train_loss: 0.287194 - train_acc: 89.13%\n",
      "Epoch 199/300 - train_loss: 0.302174 - train_acc: 89.13%\n",
      "Epoch 200/300 - train_loss: 0.303436 - train_acc: 88.57%\n",
      "Epoch 201/300 - train_loss: 0.288830 - train_acc: 89.13%\n",
      "Epoch 202/300 - train_loss: 0.290504 - train_acc: 88.96%\n",
      "Epoch 203/300 - train_loss: 0.282192 - train_acc: 89.64%\n",
      "Epoch 204/300 - train_loss: 0.283125 - train_acc: 89.40%\n",
      "Epoch 205/300 - train_loss: 0.277870 - train_acc: 89.75%\n",
      "Epoch 206/300 - train_loss: 0.285645 - train_acc: 89.87%\n",
      "Epoch 207/300 - train_loss: 0.284557 - train_acc: 89.75%\n",
      "Epoch 208/300 - train_loss: 0.284433 - train_acc: 89.74%\n",
      "Epoch 209/300 - train_loss: 0.283941 - train_acc: 89.53%\n",
      "Epoch 210/300 - train_loss: 0.295126 - train_acc: 89.13%\n",
      "Epoch 211/300 - train_loss: 0.288017 - train_acc: 89.26%\n",
      "Epoch 212/300 - train_loss: 0.285091 - train_acc: 89.68%\n",
      "Epoch 213/300 - train_loss: 0.278294 - train_acc: 89.96%\n",
      "Epoch 214/300 - train_loss: 0.273676 - train_acc: 90.21%\n",
      "Epoch 215/300 - train_loss: 0.283119 - train_acc: 90.00%\n",
      "Epoch 216/300 - train_loss: 0.310383 - train_acc: 89.32%\n",
      "Epoch 217/300 - train_loss: 0.333949 - train_acc: 89.13%\n",
      "Epoch 218/300 - train_loss: 0.344044 - train_acc: 87.92%\n",
      "Epoch 219/300 - train_loss: 0.331406 - train_acc: 88.00%\n",
      "Epoch 220/300 - train_loss: 0.333376 - train_acc: 88.47%\n",
      "Epoch 221/300 - train_loss: 0.323144 - train_acc: 88.49%\n",
      "Epoch 222/300 - train_loss: 0.291549 - train_acc: 89.49%\n",
      "Epoch 223/300 - train_loss: 0.303756 - train_acc: 88.87%\n",
      "Epoch 224/300 - train_loss: 0.301483 - train_acc: 89.02%\n",
      "Epoch 225/300 - train_loss: 0.292504 - train_acc: 89.13%\n",
      "Epoch 226/300 - train_loss: 0.284050 - train_acc: 89.58%\n",
      "Epoch 227/300 - train_loss: 0.272279 - train_acc: 90.28%\n",
      "Epoch 228/300 - train_loss: 0.268457 - train_acc: 90.38%\n",
      "Epoch 229/300 - train_loss: 0.267016 - train_acc: 90.47%\n",
      "Epoch 230/300 - train_loss: 0.267853 - train_acc: 90.49%\n",
      "Epoch 231/300 - train_loss: 0.260467 - train_acc: 90.96%\n",
      "Epoch 232/300 - train_loss: 0.267677 - train_acc: 90.58%\n",
      "Epoch 233/300 - train_loss: 0.364900 - train_acc: 89.15%\n",
      "Epoch 234/300 - train_loss: 0.492057 - train_acc: 86.08%\n",
      "Epoch 235/300 - train_loss: 0.512134 - train_acc: 85.02%\n",
      "Epoch 236/300 - train_loss: 0.633827 - train_acc: 84.34%\n",
      "Epoch 237/300 - train_loss: 0.486993 - train_acc: 85.19%\n",
      "Epoch 238/300 - train_loss: 0.409351 - train_acc: 86.00%\n",
      "Epoch 239/300 - train_loss: 0.348674 - train_acc: 87.36%\n",
      "Epoch 240/300 - train_loss: 0.331048 - train_acc: 87.60%\n",
      "Epoch 241/300 - train_loss: 0.311755 - train_acc: 88.25%\n",
      "Epoch 242/300 - train_loss: 0.298004 - train_acc: 88.96%\n",
      "Epoch 243/300 - train_loss: 0.290623 - train_acc: 89.28%\n",
      "Epoch 244/300 - train_loss: 0.289577 - train_acc: 89.36%\n",
      "Epoch 245/300 - train_loss: 0.330067 - train_acc: 88.72%\n",
      "Epoch 246/300 - train_loss: 0.294047 - train_acc: 89.47%\n",
      "Epoch 247/300 - train_loss: 0.286933 - train_acc: 89.36%\n",
      "Epoch 248/300 - train_loss: 0.280875 - train_acc: 89.92%\n",
      "Epoch 249/300 - train_loss: 0.278657 - train_acc: 90.17%\n",
      "Epoch 250/300 - train_loss: 0.274546 - train_acc: 90.13%\n",
      "Epoch 251/300 - train_loss: 0.271250 - train_acc: 90.43%\n",
      "Epoch 252/300 - train_loss: 0.272376 - train_acc: 90.15%\n",
      "Epoch 253/300 - train_loss: 0.278033 - train_acc: 90.09%\n",
      "Epoch 254/300 - train_loss: 0.278265 - train_acc: 90.30%\n",
      "Epoch 255/300 - train_loss: 0.274714 - train_acc: 89.75%\n",
      "Epoch 256/300 - train_loss: 0.268290 - train_acc: 90.55%\n",
      "Epoch 257/300 - train_loss: 0.267454 - train_acc: 90.62%\n",
      "Epoch 258/300 - train_loss: 0.263924 - train_acc: 90.51%\n",
      "Epoch 259/300 - train_loss: 0.267499 - train_acc: 90.60%\n",
      "Epoch 260/300 - train_loss: 0.263293 - train_acc: 90.79%\n",
      "Epoch 261/300 - train_loss: 0.266648 - train_acc: 90.49%\n",
      "Epoch 262/300 - train_loss: 0.265993 - train_acc: 90.36%\n",
      "Epoch 263/300 - train_loss: 0.261445 - train_acc: 90.70%\n",
      "Epoch 264/300 - train_loss: 0.257641 - train_acc: 90.91%\n",
      "Epoch 265/300 - train_loss: 0.257858 - train_acc: 90.92%\n",
      "Epoch 266/300 - train_loss: 0.256010 - train_acc: 91.13%\n",
      "Epoch 267/300 - train_loss: 0.257327 - train_acc: 91.11%\n",
      "Epoch 268/300 - train_loss: 0.266420 - train_acc: 90.45%\n",
      "Epoch 269/300 - train_loss: 0.272225 - train_acc: 90.49%\n",
      "Epoch 270/300 - train_loss: 0.275933 - train_acc: 90.17%\n",
      "Epoch 271/300 - train_loss: 0.274197 - train_acc: 90.58%\n",
      "Epoch 272/300 - train_loss: 0.260511 - train_acc: 90.70%\n",
      "Epoch 273/300 - train_loss: 0.253976 - train_acc: 91.17%\n",
      "Epoch 274/300 - train_loss: 0.282335 - train_acc: 90.38%\n",
      "Epoch 275/300 - train_loss: 0.293991 - train_acc: 89.85%\n",
      "Epoch 276/300 - train_loss: 0.306501 - train_acc: 89.53%\n",
      "Epoch 277/300 - train_loss: 0.301693 - train_acc: 89.53%\n",
      "Epoch 278/300 - train_loss: 0.281967 - train_acc: 90.09%\n",
      "Epoch 279/300 - train_loss: 0.262354 - train_acc: 90.68%\n",
      "Epoch 280/300 - train_loss: 0.254323 - train_acc: 91.06%\n",
      "Epoch 281/300 - train_loss: 0.256000 - train_acc: 91.38%\n",
      "Epoch 282/300 - train_loss: 0.315833 - train_acc: 89.87%\n",
      "Epoch 283/300 - train_loss: 0.317183 - train_acc: 90.06%\n",
      "Epoch 284/300 - train_loss: 0.325503 - train_acc: 89.85%\n",
      "Epoch 285/300 - train_loss: 0.561597 - train_acc: 87.09%\n",
      "Epoch 286/300 - train_loss: 0.439393 - train_acc: 86.74%\n",
      "Epoch 287/300 - train_loss: 0.335593 - train_acc: 88.08%\n",
      "Epoch 288/300 - train_loss: 0.305080 - train_acc: 89.42%\n",
      "Epoch 289/300 - train_loss: 0.292340 - train_acc: 89.72%\n",
      "Epoch 290/300 - train_loss: 0.276313 - train_acc: 89.79%\n",
      "Epoch 291/300 - train_loss: 0.292527 - train_acc: 89.85%\n",
      "Epoch 292/300 - train_loss: 0.274923 - train_acc: 90.02%\n",
      "Epoch 293/300 - train_loss: 0.261902 - train_acc: 90.70%\n",
      "Epoch 294/300 - train_loss: 0.258715 - train_acc: 90.94%\n",
      "Epoch 295/300 - train_loss: 0.254347 - train_acc: 91.09%\n",
      "Epoch 296/300 - train_loss: 0.253735 - train_acc: 91.23%\n",
      "Epoch 297/300 - train_loss: 0.252673 - train_acc: 91.21%\n",
      "Epoch 298/300 - train_loss: 0.249708 - train_acc: 91.32%\n",
      "Epoch 299/300 - train_loss: 0.249148 - train_acc: 91.26%\n",
      "Epoch 300/300 - train_loss: 0.247042 - train_acc: 91.32%\n"
     ]
    }
   ],
   "source": [
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HcdROfn39H1m",
    "outputId": "5719ee5b-c3a8-4955-e1d9-7b7c6fb30c91",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss:5.350982 | test_acc:90.30 | auc:0.90\n"
     ]
    }
   ],
   "source": [
    "    loss, accuracy, auc = trainer.test()\n",
    "    print('test_loss:%.6f | test_acc:%.2f | auc:%.2f' % (loss, accuracy, auc))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "gcn_link_prediction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "019bfd6e6d68453ab8302e32ff4c693e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "0e7ae792d1264c1db57e178901615630": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8b3f14adca0e4d919011a7cae002d3fd",
      "placeholder": "​",
      "style": "IPY_MODEL_52dda8a6eec84634acb241491d4b8e71",
      "value": " 1224/1224 [00:06&lt;00:00, 195.28it/s]"
     }
    },
    "52dda8a6eec84634acb241491d4b8e71": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8b3f14adca0e4d919011a7cae002d3fd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a2ec94874bad43b0a297e6e368641ce8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b7db93717d7643e4bf0777503d87cab2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "de30f42132da46f082cee8dfcf051c2f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Computing transition probabilities: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a2ec94874bad43b0a297e6e368641ce8",
      "max": 1224,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_019bfd6e6d68453ab8302e32ff4c693e",
      "value": 1224
     }
    },
    "f152c8a5153c4235bd37d9d47cf48830": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_de30f42132da46f082cee8dfcf051c2f",
       "IPY_MODEL_0e7ae792d1264c1db57e178901615630"
      ],
      "layout": "IPY_MODEL_b7db93717d7643e4bf0777503d87cab2"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
